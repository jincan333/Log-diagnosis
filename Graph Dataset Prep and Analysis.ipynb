{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:21:01.159115Z",
     "start_time": "2022-03-30T03:21:00.585936Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:21:01.819779Z",
     "start_time": "2022-03-30T03:21:01.800848Z"
    }
   },
   "outputs": [],
   "source": [
    "class msg_node:\n",
    "    msg_type = None\n",
    "    attrs = []\n",
    "    server_model = None\n",
    "    msg_time = None\n",
    "    msg_title = None\n",
    "    idx = 0\n",
    "    error_type = None\n",
    "    \n",
    "    def __init__(self, msg, log_time, server_model, error_type):\n",
    "        self.server_model = server_model\n",
    "        self.attrs = [xx.strip() for xx in msg.split('|')]\n",
    "        self.msg_time = log_time\n",
    "        if (len(self.attrs) == 1) and (self.attrs[0] == ''):\n",
    "            self.error_type = error_type\n",
    "            self.msg_type = 4\n",
    "        elif len(self.attrs) == 1:\n",
    "            self.msg_type = 0\n",
    "        elif len(self.attrs) == 2:\n",
    "            self.msg_type = 1\n",
    "            self.msg_title = self.attrs[0]\n",
    "        elif (len(self.attrs) == 3) and (self.attrs[-1] in ['Assert','Asserted','Deasserted','Deassert','asserted','deasserted']):\n",
    "            self.msg_type = 2\n",
    "            self.msg_title = self.attrs[0]\n",
    "        elif len(self.attrs) >=3:\n",
    "            self.msg_type = 3\n",
    "            self.msg_title = self.attrs[0]\n",
    "        else:\n",
    "            print('Error in extracting msg attributes!')\n",
    "    \n",
    "    def set_index(self, index):\n",
    "        self.idx = index\n",
    "\n",
    "class msg_graph:\n",
    "    nodes = []  # list of msg_node\n",
    "    edges = []  # list of tuples (msg_node_index1, msg_node_index2, edge_type, delta_time)\n",
    "    error_label = []\n",
    "    \n",
    "    def __init__(self, nodes):\n",
    "        # 注！这里默认输入的nodes是已经按照时序排好的\n",
    "        self.nodes = nodes\n",
    "        self.edges = []\n",
    "        \n",
    "    def assign_index(self):\n",
    "        for kth, node in enumerate(self.nodes):\n",
    "            node.set_index(kth)\n",
    "    \n",
    "    def build_graph(self, with_time_order = True, time_cutoff=172800):\n",
    "        edge_stamps = []\n",
    "        # edge type 1: same msg_title\n",
    "        unique_edge_types = list(set([xx.msg_title for xx in nodes]))\n",
    "        edge_type_vector = np.array([xx.msg_title for xx in nodes])\n",
    "        for kth in range(len(unique_edge_types)):\n",
    "            temp_nodes = np.array(nodes)[edge_type_vector == unique_edge_types[kth]].tolist()\n",
    "            for pth in range(len(temp_nodes)-1):\n",
    "                self.edges.append((temp_nodes[pth].idx, temp_nodes[pth+1].idx, \n",
    "                                   unique_edge_types[kth],\n",
    "                                   (temp_nodes[pth+1].msg_time - temp_nodes[pth].msg_time).seconds))\n",
    "                edge_stamps.append((temp_nodes[pth].idx, temp_nodes[pth+1].idx))\n",
    "        self.unique_edge_types = unique_edge_types\n",
    "        \n",
    "        # edge type 2: order of time\n",
    "        if with_time_order:\n",
    "            for ith in range(len(nodes)-1):\n",
    "                if not ((ith, ith+1) in edge_stamps):\n",
    "                    self.edges.append((ith, ith+1, 'time_order', (nodes[ith+1].msg_time - nodes[ith].msg_time).seconds))\n",
    "        \n",
    "        # assign error type to the graph\n",
    "        self.error_label = []\n",
    "        for ith in range(len(nodes)):\n",
    "            if not nodes[ith].error_type is None:\n",
    "                self.error_label.append(nodes[ith].error_type)\n",
    "        \n",
    "    def network_info(self):\n",
    "        node_info = [(xx.idx, {'type': xx.msg_type}) for xx in self.nodes]\n",
    "        edge_info = [(xx[0], xx[1], {'type': xx[2],'weight': 10 / (xx[3]+1e-6)}) for xx in self.edges]\n",
    "        return node_info, edge_info, self.error_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:21:13.247470Z",
     "start_time": "2022-03-30T03:21:11.346087Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('pre_contest/dataset/preliminary_sel_log_dataset.csv',sep=',')\n",
    "df2 = pd.read_csv('pre_contest/dataset/preliminary_sel_log_dataset_a.csv',sep=',')\n",
    "#df3 = pd.read_csv('pre_contest/dataset/preliminary_submit_dataset_a.csv',sep=',')\n",
    "\n",
    "select_fields = ['sn','time','msg','server_model']\n",
    "df = pd.concat([df1[select_fields], df2[select_fields]])\n",
    "df['error_type'] = ''\n",
    "df['log_time'] = pd.to_datetime(df['time'])\n",
    "df['msg_len'] = df['msg'].apply(lambda d: len(d.split('|')))\n",
    "\n",
    "df_server_mapping = df[['sn','server_model']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:21:14.268580Z",
     "start_time": "2022-03-30T03:21:14.080774Z"
    }
   },
   "outputs": [],
   "source": [
    "df1_label = pd.read_csv('pre_contest/dataset/preliminary_train_label_dataset.csv',sep=',')\n",
    "df2_label = pd.read_csv('pre_contest/dataset/preliminary_train_label_dataset_s.csv',sep=',')\n",
    "\n",
    "df_label = pd.concat([df1_label, df2_label])\n",
    "df_label['log_time'] = pd.to_datetime(df_label['fault_time'])\n",
    "df_label['msg'] = ''\n",
    "df_label['msg_len'] = 0\n",
    "df_label['server_model'] = df_label['sn'].map(dict(zip(df_server_mapping['sn'], \n",
    "                                                       df_server_mapping['server_model'])))\n",
    "df_label.columns = ['sn','time','error_type','log_time','msg','msg_len','server_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:21:15.744864Z",
     "start_time": "2022-03-30T03:21:15.464447Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comb = pd.concat([df, df_label])\n",
    "df_comb = df_comb.sort_values(['log_time'], ascending=True)\n",
    "df_comb = df_comb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:21:26.748701Z",
     "start_time": "2022-03-30T03:21:16.832578Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoff = 10 * 3600\n",
    "\n",
    "grp_store = []\n",
    "cnt_with_label = 0\n",
    "cnt_with_multi_label = 0\n",
    "cnt_miss_label = 0\n",
    "for name, grp in df_comb.groupby(['sn']):\n",
    "    grp_store.append(grp)\n",
    "    if len(grp.error_type.unique()) == 1:\n",
    "        cnt_miss_label += 1\n",
    "    elif len(grp.error_type.unique()) == 2:\n",
    "        cnt_with_label += 1\n",
    "    else:\n",
    "        prev_time = [grp['time'].iloc[0]] + grp['time'].tolist()[:-1]\n",
    "        grp['prev_time'] = pd.to_datetime(prev_time)\n",
    "        grp['delta_time'] = grp['log_time'] - grp['prev_time']\n",
    "        grp['delta_time'] = grp['delta_time'].apply(lambda d: d.seconds)\n",
    "        cutoff_idx = [0] + grp.loc[grp['delta_time'] > cutoff].index.tolist() + [grp.index.tolist()[-1]+1]\n",
    "        for kth in range(len(cutoff_idx)-1): \n",
    "            temp_grp = grp.loc[(grp.index < cutoff_idx[kth+1]) & (grp.index >= cutoff_idx[kth])]\n",
    "            grp_store.append(temp_grp)\n",
    "            if len(temp_grp.error_type.unique() == 1):\n",
    "                cnt_miss_label += 1\n",
    "            elif len(temp_grp.error_type.unique()) == 2:\n",
    "                cnt_with_label += 1\n",
    "            else:\n",
    "                cnt_with_multi_label += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:28:56.839531Z",
     "start_time": "2022-03-30T03:27:41.062602Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/dingqingyang/.conda/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "miss_store = []\n",
    "label_0_store = []\n",
    "label_1_store = []\n",
    "label_2_store = []\n",
    "label_3_store = []\n",
    "\n",
    "save_fields = ['sn','time','msg','server_model','error_type','msg_len']\n",
    "for grp in grp_store:\n",
    "    file_name = grp['sn'].iloc[0] + '__' + grp['time'].iloc[0]\n",
    "    grp['id'] = file_name\n",
    "    \n",
    "    nodes = []\n",
    "    for ith in range(len(grp)):\n",
    "        nodes.append(msg_node(grp['msg'].iloc[ith], \n",
    "                              grp['log_time'].iloc[ith], \n",
    "                              grp['server_model'].iloc[ith],\n",
    "                              grp['error_type'].iloc[ith]))\n",
    "    test_graph = msg_graph(nodes)\n",
    "    test_graph.assign_index()\n",
    "    test_graph.build_graph()\n",
    "    \n",
    "    flag = True\n",
    "    if 0 in test_graph.error_label:\n",
    "        label_0_store.append(grp)\n",
    "        flag = False\n",
    "    if 1 in test_graph.error_label:\n",
    "        label_1_store.append(grp)\n",
    "        flag = False\n",
    "    if 2 in test_graph.error_label:\n",
    "        label_2_store.append(grp)\n",
    "        flag = False\n",
    "    if 3 in test_graph.error_label:\n",
    "        label_3_store.append(grp)\n",
    "        flag = False\n",
    "    if flag:\n",
    "        miss_store.append(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:29:08.061903Z",
     "start_time": "2022-03-30T03:29:08.056670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2914, 1466, 3946, 8577, 2432)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(miss_store), len(label_0_store), len(label_1_store),len(label_2_store),len(label_3_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:31:45.605433Z",
     "start_time": "2022-03-30T03:31:44.179072Z"
    }
   },
   "outputs": [],
   "source": [
    "select_fields = ['sn','time','msg','server_model','error_type','msg_len','id','log_time']\n",
    "df0 = pd.concat(label_0_store)\n",
    "df0[select_fields].to_pickle('pre_contest/graph_dataset/label_0_dat.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:32:49.317724Z",
     "start_time": "2022-03-30T03:32:30.880487Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.concat(label_1_store)\n",
    "df1[select_fields].to_pickle('pre_contest/graph_dataset/label_1_dat.p')\n",
    "\n",
    "df2 = pd.concat(label_2_store)\n",
    "df2[select_fields].to_pickle('pre_contest/graph_dataset/label_2_dat.p')\n",
    "\n",
    "df3 = pd.concat(label_3_store)\n",
    "df3[select_fields].to_pickle('pre_contest/graph_dataset/label_3_dat.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T03:33:18.541402Z",
     "start_time": "2022-03-30T03:33:15.164887Z"
    }
   },
   "outputs": [],
   "source": [
    "df_miss = pd.concat(miss_store)\n",
    "df_miss[select_fields].to_pickle('pre_contest/graph_dataset/label_miss_dat.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
