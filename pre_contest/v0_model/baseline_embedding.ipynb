{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 引入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:45:34.007699Z",
     "start_time": "2022-03-04T03:45:19.522853Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:08:40.931146Z",
     "start_time": "2022-03-04T03:51:27.359416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jinca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:45:50.003738Z",
     "start_time": "2022-03-04T03:45:47.405697Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取sel日志，排序\n",
    "sel_data = pd.read_csv('./pre_contest/dataset/preliminary_sel_logbdataset.csv')\n",
    "sel_data.sort_values(by=['sn', 'time'], inplace=True)\n",
    "sel_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sn\n",
       "SERVER_10001      9\n",
       "SERVER_10003    117\n",
       "SERVER_10008      9\n",
       "SERVER_10009      4\n",
       "SERVER_10012      4\n",
       "               ... \n",
       "SERVER_999        4\n",
       "SERVER_9991       3\n",
       "SERVER_9993       2\n",
       "SERVER_9998       2\n",
       "SERVER_9999      16\n",
       "Length: 13705, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_data.groupby('sn').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:18:28.114054Z",
     "start_time": "2022-03-04T05:11:39.555821Z"
    }
   },
   "outputs": [],
   "source": [
    "# 取出每台服务器的最后十条日志\n",
    "sn_list = sel_data['sn'].drop_duplicates(keep='first').to_list()\n",
    "tail_msg_list = ['.'.join(sel_data[sel_data['sn']==i]['msg'].tail(10).to_list()) for i in sn_list]\n",
    "tokenized_sent = [word_tokenize(s.lower()) for s in tail_msg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:19:06.213568Z",
     "start_time": "2022-03-04T05:19:06.206153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13705, 13705)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sent), len(sn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练embbeding模型（Doc2Vec）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:24:17.511271Z",
     "start_time": "2022-03-04T05:23:41.509898Z"
    }
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]\n",
    "model = Doc2Vec(tagged_data, vector_size = 10, window = 2, min_count = 1, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:25:37.506670Z",
     "start_time": "2022-03-04T05:25:37.427768Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('./pre_contest/Doc2Vec_models/modelv1_presellog.p','wb')\n",
    "pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 构建树模型的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:46:22.614779Z",
     "start_time": "2022-03-04T05:26:04.935833Z"
    }
   },
   "outputs": [],
   "source": [
    "label = pd.read_csv('./pre_contest/dataset/preliminary_train_label_dataset.csv')\n",
    "label.sort_values(by=['sn', 'fault_time'], inplace=True)\n",
    "label.reset_index(drop=True, inplace=True)\n",
    "train_data = []\n",
    "for i, row in label.iterrows():\n",
    "    train_data.append(model.infer_vector(word_tokenize('.'.join(sel_data[(sel_data['sn']==row['sn'])&(sel_data['time']<=row['fault_time'])].tail(10)['msg']).lower())))\n",
    "train_feature = np.array(train_data)\n",
    "train_label = label['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:52:22.680044Z",
     "start_time": "2022-03-04T05:52:20.099181Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('./pre_contest/Doc2Vec_models/train_dat.v1.npy',train_feature)\n",
    "np.save('./pre_contest/Doc2Vec_models/train_labels.v1.npy', train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance evaluation\n",
    "def macro_f1(target_df: pd.DataFrame,  submit_df: pd.DataFrame)  -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param target_df: [sn,fault_time,label]\n",
    "    :param submit_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    weights =  [3  /  7,  2  /  7,  1  /  7,  1  /  7]\n",
    "    overall_df = target_df.merge(submit_df, how='left', on=['sn', 'fault_time'], suffixes=['_gt', '_pr'])\n",
    "    overall_df.fillna(-1)\n",
    "    \n",
    "    macro_F1 =  0.\n",
    "    for i in  range(len(weights)):\n",
    "        TP =  len(overall_df[(overall_df['label_gt'] == i) & (overall_df['label_pr'] == i)])\n",
    "        FP =  len(overall_df[(overall_df['label_gt'] != i) & (overall_df['label_pr'] == i)])\n",
    "        FN =  len(overall_df[(overall_df['label_gt'] == i) & (overall_df['label_pr'] != i)])\n",
    "        precision = TP /  (TP + FP)  if  (TP + FP)  >  0  else  0\n",
    "        recall = TP /  (TP + FN)  if  (TP + FN)  >  0  else  0\n",
    "        F1 =  2  * precision * recall /  (precision + recall)  if  (precision + recall)  >  0  else  0\n",
    "        macro_F1 += weights[i]  * F1\n",
    "        \n",
    "        print('Task %d:\\n Prcesion %.2f, Recall %.2f, F1 %.2f' % (i+1, precision, recall, F1))\n",
    "        \n",
    "    return macro_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:18:07.071782Z",
     "start_time": "2022-03-04T06:18:07.053125Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation dataset\n",
    "import random\n",
    "val_mask = [random.random() < 0.2 for _ in range(len(train_label))]\n",
    "train_mask = [not xx for xx in val_mask]\n",
    "val_feature = train_feature[val_mask]\n",
    "val_label = train_label[val_mask]\n",
    "\n",
    "train_feat = train_feature[train_mask]\n",
    "train_lab = train_label[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:18:31.775903Z",
     "start_time": "2022-03-04T06:18:28.107019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True)\n",
    "rf.fit(train_feat, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:19:06.552022Z",
     "start_time": "2022-03-04T06:19:06.279930Z"
    }
   },
   "outputs": [],
   "source": [
    "train_label_pred = rf.predict(train_feature)\n",
    "submit_df = label[['sn','fault_time']]\n",
    "submit_df['label'] = train_label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:19:40.057458Z",
     "start_time": "2022-03-04T06:19:39.947808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1:\n",
      " Prcesion 0.46, Recall 0.07, F1 0.13\n",
      "Task 2:\n",
      " Prcesion 0.53, Recall 0.53, F1 0.53\n",
      "Task 3:\n",
      " Prcesion 0.78, Recall 0.93, F1 0.85\n",
      "Task 4:\n",
      " Prcesion 0.56, Recall 0.44, F1 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3990924560173966"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(label.loc[val_mask], submit_df.loc[val_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:20:12.837303Z",
     "start_time": "2022-03-04T06:20:12.790481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1:\n",
      " Prcesion 1.00, Recall 1.00, F1 1.00\n",
      "Task 2:\n",
      " Prcesion 1.00, Recall 1.00, F1 1.00\n",
      "Task 3:\n",
      " Prcesion 1.00, Recall 1.00, F1 1.00\n",
      "Task 4:\n",
      " Prcesion 1.00, Recall 0.99, F1 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9979683096583338"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(label.loc[train_mask], submit_df.loc[train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 构建测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:58:23.915758Z",
     "start_time": "2022-03-04T05:53:28.800889Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./pre_contest/dataset/preliminary_submit_dataset_a.csv')\n",
    "submit.sort_values(by=['sn', 'fault_time'], inplace=True)\n",
    "submit.reset_index(drop=True, inplace=True)\n",
    "test_data = []\n",
    "for i, row in submit.iterrows():\n",
    "    test_data.append(model.infer_vector(word_tokenize('. '.join(sel_data[(sel_data['sn']==row['sn'])&(sel_data['time']<=row['fault_time'])].tail(10)['msg']).lower())))\n",
    "test_feature = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 预测并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:58:47.554860Z",
     "start_time": "2022-03-04T05:58:47.273661Z"
    }
   },
   "outputs": [],
   "source": [
    "test_label = rf.predict(test_feature)\n",
    "submit['label'] = test_label\n",
    "submit.to_csv('./pre_contest/output/preliminary_pred_df.v1.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Log_diagosis_python",
   "language": "python",
   "name": "log_diagosis_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
