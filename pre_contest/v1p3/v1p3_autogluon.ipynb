{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c0ace7",
   "metadata": {},
   "source": [
    "# 背景：使用autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7456b",
   "metadata": {},
   "source": [
    "## 导包、设置根目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2893e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jincan02/Projects/Log-diagnosis\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import datetime\n",
    "\n",
    "from autogluon.tabular import TabularDataset,TabularPredictor\n",
    "\n",
    "# 更改工作目录为当前项目根目录\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.chdir(os.path.dirname(os.path.dirname(sys.path[0])))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c455b9",
   "metadata": {},
   "source": [
    "## 读取日志和标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a858c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1460\n",
       "1    3016\n",
       "2    7731\n",
       "3    2214\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.read_csv('./pre_contest/v1p2/word_label_df.txt',sep='\\t',index_col=0)\n",
    "log_list=list(word_df['log'])\n",
    "label_list=list(word_df['label'])\n",
    "word_df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e588350",
   "metadata": {},
   "source": [
    "## 读取v1p2特征重要性前300的特征作为本次使用的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fad9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_top_300_df=pd.read_csv('./pre_contest/v1p2/feature_importance_top_300_df.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1938ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>day</th>\n",
       "      <th>label</th>\n",
       "      <th>memory</th>\n",
       "      <th>or</th>\n",
       "      <th>cpu</th>\n",
       "      <th>processor</th>\n",
       "      <th>caterr</th>\n",
       "      <th>configuration</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>check</th>\n",
       "      <th>0xe1</th>\n",
       "      <th>f1</th>\n",
       "      <th>cycle</th>\n",
       "      <th>disk10</th>\n",
       "      <th>0xec</th>\n",
       "      <th>button</th>\n",
       "      <th>dimmg1_temp</th>\n",
       "      <th>cpu1_c1d1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SERVER_10001</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SERVER_10003</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SERVER_10008</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SERVER_10008</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SERVER_10009</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sn         day  label  memory  or  cpu  processor  caterr  \\\n",
       "0  SERVER_10001  2020-05-01      1       0   9    4          4       0   \n",
       "1  SERVER_10003  2020-03-28      2       1   2    1          0       0   \n",
       "2  SERVER_10008  2020-02-25      1       1   5    2          2       0   \n",
       "3  SERVER_10008  2020-03-11      2       1   5    2          2       0   \n",
       "4  SERVER_10009  2020-05-08      3       0   0    0          0       0   \n",
       "\n",
       "   configuration   e  ...  36  check  0xe1  f1  cycle  disk10  0xec  button  \\\n",
       "0              0  60  ...   0      0     0   0      0       0     0       0   \n",
       "1              0   6  ...   0      0     0   0      0       0     0       0   \n",
       "2              1  14  ...   0      0     0   0      0       0     0       0   \n",
       "3              1  20  ...   0      0     0   0      0       0     0       0   \n",
       "4              0  18  ...   0      0     0   0      0       0     0       0   \n",
       "\n",
       "   dimmg1_temp  cpu1_c1d1  \n",
       "0            0          0  \n",
       "1            0          0  \n",
       "2            0          0  \n",
       "3            0          0  \n",
       "4            0          0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_top_300_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb3829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_list=list(feature_importance_top_300_df.columns)[3:33]\n",
    "feature_df=feature_importance_top_300_df[feature_names_list]\n",
    "label_list=list(feature_importance_top_300_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d5f75",
   "metadata": {},
   "source": [
    "## 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb519f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "val_mask = [random.random() < 0.3 for _ in range(len(feature_df))]\n",
    "train_mask = [not xx for xx in val_mask]\n",
    "train_data=feature_importance_top_300_df[['label']+feature_names_list][train_mask]\n",
    "label=np.array(label_list)\n",
    "val_feature = feature_df[val_mask]\n",
    "val_label = label[val_mask]\n",
    "train_feature = feature_df[train_mask]\n",
    "train_label = label[train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1486e9",
   "metadata": {},
   "source": [
    "## 使用autogluon训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81145d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"pre_contest/v1p3/autogluon\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"pre_contest/v1p3/autogluon/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    10133\n",
      "Train Data Columns: 30\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t4 unique label values:  [1, 2, 3, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5730.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 30 | ['memory', 'or', 'cpu', 'processor', 'caterr', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 30 | ['memory', 'or', 'cpu', 'processor', 'caterr', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t30 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.43 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 9119, Val Rows: 1014\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n"
     ]
    }
   ],
   "source": [
    "save_path='pre_contest/v1p3/autogluon'\n",
    "predictor=TabularPredictor(label='label',eval_metric='f1_macro',path=save_path).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b292500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指标评估\n",
    "def macro_f1(label,prediction)  -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param target_df: [sn,fault_time,label]\n",
    "    :param submit_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    weights =  [3  /  7,  2  /  7,  1  /  7,  1  /  7]\n",
    "    macro_F1 =  0.\n",
    "    for i in  range(len(weights)):\n",
    "        TP =  np.sum((label==i) & (prediction==i))\n",
    "        FP =  np.sum((label!= i) & (prediction == i))\n",
    "        FN =  np.sum((label == i) & (prediction!= i))\n",
    "        precision = TP /  (TP + FP)  if  (TP + FP)  >  0  else  0\n",
    "        recall = TP /  (TP + FN)  if  (TP + FN)  >  0  else  0\n",
    "        F1 =  2  * precision * recall /  (precision + recall)  if  (precision + recall)  >  0  else  0\n",
    "        macro_F1 += weights[i]  * F1\n",
    "        \n",
    "        print('Task %d:\\n Prcesion %.2f, Recall %.2f, F1 %.2f' % (i+1, precision, recall, F1))\n",
    "        \n",
    "    return macro_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c759e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1(train_label,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9327053",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1(val_label,val_pred)\n",
    "# 采用所有词的词频向量比采用词频+word2vec效果更佳"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Log_diagnosis",
   "language": "python",
   "name": "log_diagnosis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
