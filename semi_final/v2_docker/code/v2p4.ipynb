{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ac94bf",
   "metadata": {},
   "source": [
    "# 调整随机投票的日志匹配方式为最近邻时间匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d587f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from logging import handlers\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import traceback\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "## 日志格式设置\n",
    "# 日志级别关系映射\n",
    "level_relations = {\n",
    "    'debug': logging.DEBUG,\n",
    "    'info': logging.INFO,\n",
    "    'warning': logging.WARNING,\n",
    "    'error': logging.ERROR,\n",
    "    'crit': logging.CRITICAL\n",
    "}\n",
    "def get_logger(filename, level='info'):\n",
    "    # 创建日志对象\n",
    "    log = logging.getLogger(filename)\n",
    "    # 设置日志级别\n",
    "    log.setLevel(level_relations.get(level))\n",
    "    # 日志输出格式\n",
    "    fmt = logging.Formatter('%(asctime)s %(thread)d %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "    # 输出到控制台\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(fmt)\n",
    "    # 输出到文件\n",
    "    # 日志文件按天进行保存，每天一个日志文件\n",
    "    file_handler = handlers.TimedRotatingFileHandler(filename=filename, when='D', backupCount=1, encoding='utf-8')\n",
    "    # 按照大小自动分割日志文件，一旦达到指定的大小重新生成文件\n",
    "    # file_handler = handlers.RotatingFileHandler(filename=filename, maxBytes=1*1024*1024*1024, backupCount=1, encoding='utf-8')\n",
    "    file_handler.setFormatter(fmt)\n",
    "    if not log.handlers:\n",
    "        log.addHandler(console_handler)\n",
    "        log.addHandler(file_handler)\n",
    "    return log\n",
    "\n",
    "# sn分组后，本次报错和上次报错之间的日志匹配到本次报错\n",
    "def divideLogByFaultTime(log_label_df: pd.DataFrame):\n",
    "    log_correspond_label_df = pd.DataFrame(columns=['sn', 'fault_time', 'msg', 'time', 'server_model', 'label'])\n",
    "    no_label_log_list = []\n",
    "    log_label_df = log_label_df.reset_index(drop=True)\n",
    "\n",
    "    for sn, log in log_label_df.groupby('sn'):\n",
    "        if len(log[log['label'] != '']) == 0:\n",
    "            no_label_log_list.append(log)\n",
    "        elif len(log[log['label'] != '']) == 1:\n",
    "            msg_df = log[log['label'] == '']\n",
    "            msg_df['label'] = log[log['label'] != '']['label'].iloc[0]\n",
    "            msg_df['fault_time'] = log[log['label'] != '']['time'].iloc[0]\n",
    "            log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "        else:\n",
    "            # 使用index的顺序取数时，要注意index必须按所需的顺序排列\n",
    "            cutoff_index = [-1] + log.loc[log['label'] != ''].index.tolist() + [log.index.tolist()[-1] + 1]\n",
    "            for kth in range(len(cutoff_index) - 1):\n",
    "                temp_log = log.loc[(log.index <= cutoff_index[kth + 1]) & (log.index > cutoff_index[kth])]\n",
    "                if len(temp_log) > 0:\n",
    "                    if len(temp_log[temp_log['label'] != '']) == 0:\n",
    "                        no_label_log_list.append(temp_log)\n",
    "                    # 只有标签，没有日志的数据，把标签的部分数据直接作为日志\n",
    "                    elif len(temp_log) == 1:\n",
    "                        msg_df = temp_log\n",
    "                        msg_df['fault_time'] = temp_log[temp_log['label'] != '']['time'].iloc[0]\n",
    "                        log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "                    else:\n",
    "                        msg_df = temp_log[temp_log['label'] == '']\n",
    "                        msg_df['label'] = temp_log[temp_log['label'] != '']['label'].iloc[0]\n",
    "                        msg_df['fault_time'] = temp_log[temp_log['label'] != '']['time'].iloc[0]\n",
    "                        log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "    return log_correspond_label_df, no_label_log_list\n",
    "\n",
    "# sn分组后，按照最近邻+时间间隔划分日志数据\n",
    "def divideLogByNearestTime(log_label_df: pd.DataFrame):\n",
    "    log_correspond_label_df = pd.DataFrame(columns=['sn', 'fault_time', 'msg', 'time', 'server_model', 'label'])\n",
    "    no_label_log_list = []\n",
    "    cutoff = 10 * 3600\n",
    "\n",
    "    for sn, log in log_label_df.groupby('sn'):\n",
    "        if len(log[log['label'] != '']) == 0:\n",
    "            no_label_log_list.append(log)\n",
    "        elif len(log[log['label'] != '']) == 1:\n",
    "            msg_df = log[log['label'] == '']\n",
    "            msg_df['label'] = log[log['label'] != '']['label'].iloc[0]\n",
    "            msg_df['fault_time'] = log[log['label'] != '']['time'].iloc[0]\n",
    "            log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "        else:\n",
    "            lable_df = log[log['label'] != '']\n",
    "            msg_df = log[log['label'] == '']\n",
    "            for msg_item in msg_df.iterrows():\n",
    "                previous_delta_time = 1000 * 24 * 3600\n",
    "                for lable_item in lable_df.iterrows():\n",
    "                    now_delta_time = abs(datetime.strptime(lable_item[1]['time'],'%Y-%m-%d %H:%M:%S'\n",
    "                        ) - datetime.strptime(msg_item[1]['time'],'%Y-%m-%d %H:%M:%S'))\n",
    "                    if now_delta_time.days * 24 * 3600 + now_delta_time.seconds < previous_delta_time:\n",
    "                        previous_delta_time = now_delta_time.days * 24 * 3600 + now_delta_time.seconds\n",
    "                        final_lable = lable_item[1]\n",
    "                        if previous_delta_time < cutoff:\n",
    "                            msg_item[1]['fault_time'] = lable_item[1]['time']\n",
    "                            msg_item[1]['label'] = lable_item[1]['label']\n",
    "            log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df]) \n",
    "    log_correspond_label_df = log_correspond_label_df[log_correspond_label_df['label'] != '']\n",
    "    return log_correspond_label_df, no_label_log_list\n",
    "\n",
    "# 计算统计特征\n",
    "def calculateStatisticFeature(log_correspond_label_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    use_log_label_df = log_correspond_label_df\n",
    "\n",
    "    use_log_label_df['msg_hour'] = use_log_label_df['time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    use_log_label_df['msg_minute'] = use_log_label_df['time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").minute)\n",
    "    use_log_label_df['fault_hour'] = use_log_label_df['fault_time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    use_log_label_df['fault_minute'] = use_log_label_df['fault_time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").minute)\n",
    "\n",
    "    # 0408新增\n",
    "    # 最近一次日志时间距报错时间间隔，单位秒\n",
    "    nearest_msg_fault_time_delta_list = []\n",
    "    # 日志不去重时长度1,2,3,4日志数量统计\n",
    "    all_msg_1_cnt_list = []\n",
    "    all_msg_2_cnt_list = []\n",
    "    all_msg_3_cnt_list = []\n",
    "    all_msg_4_cnt_list = []\n",
    "\n",
    "    fault_minute_list = []\n",
    "    msg_1_cnt_list = []\n",
    "    msg_2_cnt_list = []\n",
    "    msg_3_cnt_list = []\n",
    "    msg_4_cnt_list = []\n",
    "    msg_hour_max_list = []\n",
    "    msg_hour_min_list = []\n",
    "    msg_hour_avg_list = []\n",
    "    msg_hour_median_list = []\n",
    "    msg_hour_mode_list = []\n",
    "    msg_minute_max_list = []\n",
    "    msg_minute_min_list = []\n",
    "    msg_minute_avg_list = []\n",
    "    msg_minute_median_list = []\n",
    "    msg_minute_mode_list = []\n",
    "\n",
    "    sn_list = []\n",
    "    server_model_list = []\n",
    "    msg_log_list = []\n",
    "    msg_cnt_list = []\n",
    "    fault_hour_list = []\n",
    "    label_list = []\n",
    "    fault_time_list = []\n",
    "    for msg_log_df in use_log_label_df.groupby(['sn', 'fault_time', 'label']):\n",
    "        msg_log_str = ''\n",
    "        all_msg_1_cnt = 0\n",
    "        all_msg_2_cnt = 0\n",
    "        all_msg_3_cnt = 0\n",
    "        all_msg_4_cnt = 0\n",
    "        msg_1_cnt = 0\n",
    "        msg_2_cnt = 0\n",
    "        msg_3_cnt = 0\n",
    "        msg_4_cnt = 0\n",
    "        for info in msg_log_df[1]['msg']:\n",
    "            if info == info:\n",
    "                if len(info.split('|')) == 1:\n",
    "                    all_msg_1_cnt += 1\n",
    "                elif len(info.split('|')) == 2:\n",
    "                    all_msg_2_cnt += 1\n",
    "                elif len(info.split('|')) == 3:\n",
    "                    all_msg_3_cnt += 1\n",
    "                else:\n",
    "                    all_msg_4_cnt += 1\n",
    "        for info in msg_log_df[1]['msg'].drop_duplicates():\n",
    "            if info == info:\n",
    "                msg_log_str = msg_log_str + info.lower() + '.'\n",
    "                if len(info.split('|')) == 1:\n",
    "                    msg_1_cnt += 1\n",
    "                elif len(info.split('|')) == 2:\n",
    "                    msg_2_cnt += 1\n",
    "                elif len(info.split('|')) == 3:\n",
    "                    msg_3_cnt += 1\n",
    "                else:\n",
    "                    msg_4_cnt += 1\n",
    "        nearest_msg_fault_time_delta = abs(datetime.strptime(msg_log_df[1].iloc[-1]['time'], '%Y-%m-%d %H:%M:%S'\n",
    "                                                             ) - datetime.strptime(msg_log_df[0][1],\n",
    "                                                                                   '%Y-%m-%d %H:%M:%S'))\n",
    "        nearest_msg_fault_time_delta = nearest_msg_fault_time_delta.days * 24 * 3600 + nearest_msg_fault_time_delta.seconds\n",
    "        sm = int(msg_log_df[1].iloc[0]['server_model'][2:])\n",
    "\n",
    "        sn_list.append(msg_log_df[0][0])\n",
    "        fault_time_list.append(msg_log_df[0][1])\n",
    "        label_list.append(msg_log_df[0][2])\n",
    "\n",
    "        nearest_msg_fault_time_delta_list.append(nearest_msg_fault_time_delta)\n",
    "        server_model_list.append(sm)\n",
    "        msg_log_list.append(msg_log_str)\n",
    "        msg_cnt_list.append(len(msg_log_df[1]))\n",
    "\n",
    "        fault_hour_list.append(msg_log_df[1].iloc[0]['fault_hour'])\n",
    "        fault_minute_list.append(msg_log_df[1].iloc[0]['fault_minute'])\n",
    "\n",
    "        all_msg_1_cnt_list.append(all_msg_1_cnt)\n",
    "        all_msg_2_cnt_list.append(all_msg_2_cnt)\n",
    "        all_msg_3_cnt_list.append(all_msg_3_cnt)\n",
    "        all_msg_4_cnt_list.append(all_msg_4_cnt)\n",
    "\n",
    "        msg_1_cnt_list.append(msg_1_cnt)\n",
    "        msg_2_cnt_list.append(msg_2_cnt)\n",
    "        msg_3_cnt_list.append(msg_3_cnt)\n",
    "        msg_4_cnt_list.append(msg_4_cnt)\n",
    "\n",
    "        msg_hour_max_list.append(msg_log_df[1]['msg_hour'].max())\n",
    "        msg_hour_min_list.append(msg_log_df[1]['msg_hour'].min())\n",
    "        msg_hour_avg_list.append(msg_log_df[1]['msg_hour'].mean())\n",
    "        msg_hour_median_list.append(msg_log_df[1]['msg_hour'].median())\n",
    "        msg_hour_mode_list.append(msg_log_df[1]['msg_hour'].mode()[0])\n",
    "\n",
    "        msg_minute_max_list.append(msg_log_df[1]['msg_minute'].max())\n",
    "        msg_minute_min_list.append(msg_log_df[1]['msg_minute'].min())\n",
    "        msg_minute_avg_list.append(msg_log_df[1]['msg_minute'].mean())\n",
    "        msg_minute_median_list.append(msg_log_df[1]['msg_minute'].median())\n",
    "        msg_minute_mode_list.append(msg_log_df[1]['msg_minute'].mode()[0])\n",
    "\n",
    "    msg_log_label_df = pd.DataFrame(\n",
    "        {\n",
    "            'sn': sn_list,\n",
    "            'fault_time': fault_time_list,\n",
    "            'server_model': server_model_list,\n",
    "            'msg_cnt': msg_cnt_list,\n",
    "            'fault_hour': fault_hour_list,\n",
    "            'fault_minute': fault_minute_list,\n",
    "            'nearest_msg_fault_time_delta': nearest_msg_fault_time_delta_list,\n",
    "            'all_msg_1_cnt': all_msg_1_cnt_list,\n",
    "            'all_msg_2_cnt': all_msg_2_cnt_list,\n",
    "            'all_msg_3_cnt': all_msg_3_cnt_list,\n",
    "            'all_msg_4_cnt': all_msg_4_cnt_list,\n",
    "            'msg_1_cnt': msg_1_cnt_list,\n",
    "            'msg_2_cnt': msg_2_cnt_list,\n",
    "            'msg_3_cnt': msg_3_cnt_list,\n",
    "            'msg_4_cnt': msg_4_cnt_list,\n",
    "            'msg_hour_max': msg_hour_max_list,\n",
    "            'msg_hour_min': msg_hour_min_list,\n",
    "            'msg_hour_avg': msg_hour_avg_list,\n",
    "            'msg_hour_median': msg_hour_median_list,\n",
    "            'msg_hour_mode': msg_hour_mode_list,\n",
    "            'msg_minute_max': msg_minute_max_list,\n",
    "            'msg_minute_min': msg_minute_min_list,\n",
    "            'msg_minute_avg': msg_minute_avg_list,\n",
    "            'msg_minute_median': msg_minute_median_list,\n",
    "            'msg_minute_mode': msg_minute_mode_list,\n",
    "            'msg_log': msg_log_list,\n",
    "            'label': label_list\n",
    "        }\n",
    "    )\n",
    "    return msg_log_label_df\n",
    "\n",
    "# 计算特征函数\n",
    "def caculateFeature(log_df: pd.DataFrame, label_df: pd.DataFrame, word_list: list) -> pd.DataFrame:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    logger.info('开始拼接日志和标签数据')\n",
    "    log_df['label'] = ''\n",
    "    label_df['time'] = label_df['fault_time']\n",
    "    label_df['msg'] = ''\n",
    "    label_df['server_model'] = label_df['sn'].map(dict(zip(log_df['sn'], log_df['server_model'])))\n",
    "    label_df = label_df[['sn', 'time', 'msg', 'server_model', 'label']]\n",
    "    log_label_df = pd.concat([log_df, label_df], axis=0).sort_values(by='time')\n",
    "    log_label_df['fault_time'] = ''\n",
    "    log_label_df = log_label_df[['sn', 'fault_time', 'msg', 'time', 'server_model', 'label']]\n",
    "    logger.info('拼接日志和标签数据结束')\n",
    "\n",
    "    logger.info('开始匹配日志和标签')\n",
    "    logger.info('使用报错时间截断进行划分')\n",
    "    # 使用报错时间截断进行划分\n",
    "#     NearestTime_log_correspond_label_df, NearestTime_no_label_log_list = divideLogByNearestTime(log_label_df)\n",
    "#     NearestTime_log_correspond_label_df.to_csv('./user_data/tmp_data/NearestTime_log_correspond_label_df.csv', index = None)\n",
    "    NearestTime_log_correspond_label_df = pd.read_csv('./user_data/tmp_data/NearestTime_log_correspond_label_df.csv')\n",
    "#     FaultTime_log_correspond_label_df, FaultTime_no_label_log_list = divideLogByFaultTime(log_label_df)\n",
    "#     FaultTime_log_correspond_label_df.to_csv('./user_data/tmp_data/FaultTime_log_correspond_label_df.csv', index = None)\n",
    "#     FaultTime_log_correspond_label_df = pd.read_csv('./user_data/tmp_data/FaultTime_log_correspond_label_df.csv')\n",
    "    logger.info('匹配日志和标签结束')\n",
    "\n",
    "    logger.info('开始计算统计特征')\n",
    "    # 使用报错时间截断进行划分\n",
    "    msg_log_label_df = calculateStatisticFeature(NearestTime_log_correspond_label_df)\n",
    "    logger.info('计算统计特征结束')\n",
    "\n",
    "    msg_log_list = list(msg_log_label_df['msg_log'])\n",
    "    label_list = list(msg_log_label_df['label'])\n",
    "\n",
    "    # 计算词频向量\n",
    "    logger.info('开始计算词频特征')\n",
    "    frequency_vector_list = []\n",
    "    tag = 0\n",
    "    for word in word_list:\n",
    "        if tag % 100 == 0:\n",
    "            print(tag, datetime.now())\n",
    "        pattern = re.compile(word)\n",
    "        frequency_vector = [len(re.findall(pattern, log)) for log in msg_log_list]\n",
    "        frequency_vector_list.append(frequency_vector)\n",
    "        tag += 1\n",
    "    logger.info('计算词频特征结束')\n",
    "\n",
    "    frequency_vector_df = pd.DataFrame(frequency_vector_list)\n",
    "    frequency_vector_df = frequency_vector_df.T\n",
    "    frequency_vector_df.columns = word_list\n",
    "    statistic_feature_list = list(msg_log_label_df.columns)[2:-2]\n",
    "    feature_df = frequency_vector_df\n",
    "    feature_df[statistic_feature_list] = msg_log_label_df[statistic_feature_list]\n",
    "\n",
    "    feature_df['label'] = label_list\n",
    "    feature_df[['sn', 'fault_time']] = msg_log_label_df[['sn', 'fault_time']]\n",
    "    logger.info('最后3列为: label, sn, fault_time, 其余列均为特征')\n",
    "    logger.info('数据条数: {}, 特征个数: {}'.format(feature_df.shape[0], feature_df.shape[1]-3))\n",
    "    return feature_df\n",
    "\n",
    "\n",
    "# xgb模型参数\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类问题\n",
    "    'num_class': 4,  # 类别数，与multi softmax并用\n",
    "    'gamma': 0.1,  # 用于控制是否后剪枝的参数，越大越保守，一般0.1 0.2的样子\n",
    "    'max_depth': 6,  # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,  # 控制模型复杂度的权重值的L2 正则化项参数，参数越大，模型越不容易过拟合\n",
    "    'subsample': 1,  # 随机采样训练样本\n",
    "    'colsample_bytree': 1,  # 这个参数默认为1，是每个叶子里面h的和至少是多少\n",
    "    # 对于正负样本不均衡时的0-1分类而言，假设h在0.01附近，min_child_weight为1\n",
    "    # 意味着叶子节点中最少需要包含100个样本。这个参数非常影响结果，\n",
    "    # 控制叶子节点中二阶导的和的最小值，该参数值越小，越容易过拟合\n",
    "    'silent': 0,  # 设置成1 则没有运行信息输入，最好是设置成0\n",
    "    'eta': 0.3,  # 如同学习率\n",
    "    'seed': 1000,\n",
    "    'nthread': 16,  # CPU线程数\n",
    "    # 'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "# 指标评估\n",
    "def macro_f1(label_df: pd.DataFrame, prediction_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param label_df: [sn,fault_time,label]\n",
    "    :param prediction_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    prediction_df.columns = ['sn', 'fault_time', 'prediction']\n",
    "    outcome_df = pd.merge(label_df, prediction_df ,how = 'left', on = ['sn', 'fault_time'])\n",
    "    weights = [5 / 11, 4 / 11, 1 / 11, 1 / 11]\n",
    "    macro_F1 = 0.\n",
    "    for i in range(len(weights)):\n",
    "        TP = len(outcome_df[(outcome_df['label'] == i) & (outcome_df['prediction'] == i)])\n",
    "        FP = len(outcome_df[(outcome_df['label'] != i) & (outcome_df['prediction'] == i)])\n",
    "        FN = len(outcome_df[(outcome_df['label'] == i) & (outcome_df['prediction'] != i)])\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        F1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        macro_F1 += weights[i] * F1\n",
    "        logger.info('Label {}:   Precision {: .2f}, Recall {: .2f}, F1 {: .2f}'.format(i, precision, recall, F1))\n",
    "    logger.info('macro_f1: {}\\n'.format(macro_F1))\n",
    "\n",
    "    return macro_F1\n",
    "\n",
    "# 模型训练函数\n",
    "def xgbTrain(feature_df: pd.DataFrame) -> xgb.XGBModel:\n",
    "    '''\n",
    "    feature_df: 要求最后3列为: label, sn, fault_time, 其余列均为特征\n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    feature_name_list = list(feature_df.columns)[0:-3]\n",
    "    feature = np.array(feature_df[feature_name_list])\n",
    "    label = np.array(feature_df['label'])\n",
    "    label_df = feature_df[['sn', 'fault_time', 'label']]\n",
    "    prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "    train_data = xgb.DMatrix(feature, label=label)\n",
    "    train_feature = xgb.DMatrix(feature)\n",
    "    logger.info('开始训练xgb模型')\n",
    "    xgb_model = xgb.train(xgb_params, train_data, num_boost_round=500)\n",
    "    logger.info('训练xgb模型结束')\n",
    "    # 训练集指标评估\n",
    "    prediction = xgb_model.predict(train_feature)\n",
    "    prediction_df['label'] = prediction\n",
    "    logger.info('训练集评估效果: ')\n",
    "    macro_f1(label_df, prediction_df)\n",
    "\n",
    "    return xgb_model\n",
    "\n",
    "# xgb模型预测函数\n",
    "def xgbPredict(model: xgb.XGBModel, feature_df: pd.DataFrame, label_df = None) -> pd.DataFrame:\n",
    "    '''\n",
    "        feature_df: 要求最后3列为: label, sn, fault_time, 其余列均为特征\n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    if label_df is None:\n",
    "        feature_name_list = list(feature_df.columns)[0:-3]\n",
    "        feature = np.array(feature_df[feature_name_list])\n",
    "        prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "        test_feature = xgb.DMatrix(feature)\n",
    "        logger.info('开始xgb模型预测')\n",
    "        prediction = model.predict(test_feature)\n",
    "        logger.info('xgb模型预测结束')\n",
    "        prediction_df['label'] = prediction\n",
    "        prediction_df['label'] = prediction_df['label'].apply(lambda x: int(x))\n",
    "\n",
    "    else:\n",
    "        feature_name_list = list(feature_df.columns)[0:-3]\n",
    "        feature = np.array(feature_df[feature_name_list])\n",
    "        prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "        test_feature = xgb.DMatrix(feature)\n",
    "        logger.info('开始xgb模型预测')\n",
    "        prediction = model.predict(test_feature)\n",
    "        logger.info('xgb模型预测结束')\n",
    "        # 测试集指标评估\n",
    "        prediction_df['label'] = prediction\n",
    "        prediction_df['label'] = prediction_df['label'].apply(lambda x: int(x))\n",
    "        logger.info('测试集评估效果: ')\n",
    "        macro_f1(label_df, prediction_df)\n",
    "\n",
    "    return prediction_df\n",
    "\n",
    "\n",
    "# xgb模型随机训练并投票预测\n",
    "def xgbRandomTrainPredict(train_feature_df: pd.DataFrame, test_feature_df: pd.DataFrame, label_df = None) -> pd.DataFrame:\n",
    "    ## 每个子模型样本均衡，利用投票规则生成最终预测\n",
    "    random.seed(0)\n",
    "    N = 100 # number of the models\n",
    "    num_sample = 500 # number of samples for each label\n",
    "\n",
    "    _label0_index_list = list(train_feature_df[train_feature_df['label'] == 0].index)\n",
    "    _label1_index_list = list(train_feature_df[train_feature_df['label'] == 1].index)\n",
    "    _label2_index_list = list(train_feature_df[train_feature_df['label'] == 2].index)\n",
    "    _label3_index_list = list(train_feature_df[train_feature_df['label'] == 3].index)\n",
    "    feature_name_list = list(train_feature_df.columns)[0:-3]\n",
    "    test_feature = np.array(test_feature_df[feature_name_list])\n",
    "    test_feature = xgb.DMatrix(test_feature)\n",
    "    prediction_df = test_feature_df[['sn', 'fault_time']]\n",
    "\n",
    "    for iter in np.arange(N):\n",
    "        idx_0 = random.sample(_label0_index_list, num_sample)\n",
    "        idx_1 = random.sample(_label1_index_list, num_sample)\n",
    "        idx_2 = random.sample(_label2_index_list, num_sample)\n",
    "        idx_3 = random.sample(_label3_index_list, num_sample)\n",
    "        idx = np.hstack((idx_0, idx_1, idx_2, idx_3))\n",
    "        random.shuffle(idx)\n",
    "        sub_train_feature_df = train_feature_df.loc[idx, :]\n",
    "        sub_train_feature = np.array(sub_train_feature_df[feature_name_list])\n",
    "        sub_train_label = np.array(sub_train_feature_df['label'])\n",
    "        sub_train_data = xgb.DMatrix(sub_train_feature,label = sub_train_label)\n",
    "\n",
    "        logger.info('开始第{}轮训练和预测'.format(iter))\n",
    "        sub_xgb_model = xgb.train(xgb_params, sub_train_data, num_boost_round=500)\n",
    "        sub_test_pred = sub_xgb_model.predict(test_feature)\n",
    "        if iter == 0:\n",
    "            val_pred = sub_test_pred\n",
    "        else:\n",
    "            val_pred = np.vstack((val_pred, sub_test_pred))\n",
    "        logger.info('第{}轮训练和预测结束'.format(iter))\n",
    "\n",
    "    # 训练集指标评估\n",
    "    final_pred = [np.argmax(np.bincount(val_pred[:, i].astype(int))) for i in np.arange(val_pred.shape[1])]\n",
    "    final_pred = np.array(final_pred).astype(int)\n",
    "    prediction_df['label'] = final_pred\n",
    "    logger.info('训练集评估效果: ')\n",
    "    macro_f1(label_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56371e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:29:11,766 13012 608450915.py[line:268] - INFO: 开始拼接日志和标签数据\n",
      "2022-05-14 23:29:12,286 13012 608450915.py[line:277] - INFO: 拼接日志和标签数据结束\n",
      "2022-05-14 23:29:12,286 13012 608450915.py[line:279] - INFO: 开始匹配日志和标签\n",
      "2022-05-14 23:29:12,287 13012 608450915.py[line:280] - INFO: 使用报错时间截断进行划分\n",
      "2022-05-14 23:34:47,412 13012 608450915.py[line:287] - INFO: 匹配日志和标签结束\n",
      "2022-05-14 23:34:47,412 13012 608450915.py[line:289] - INFO: 开始计算统计特征\n",
      "2022-05-14 23:35:14,013 13012 608450915.py[line:292] - INFO: 计算统计特征结束\n",
      "2022-05-14 23:35:14,016 13012 608450915.py[line:298] - INFO: 开始计算词频特征\n",
      "0 2022-05-14 23:35:14.016738\n",
      "100 2022-05-14 23:35:15.722737\n",
      "200 2022-05-14 23:35:17.371736\n",
      "2022-05-14 23:35:18,678 13012 608450915.py[line:308] - INFO: 计算词频特征结束\n",
      "2022-05-14 23:35:19,572 13012 608450915.py[line:319] - INFO: 最后3列为: label, sn, fault_time, 其余列均为特征\n",
      "2022-05-14 23:35:19,573 13012 608450915.py[line:320] - INFO: 数据条数: 15879, 特征个数: 303\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(sys.path[0]))\n",
    "# 忽略warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "# 读取sel日志数据\n",
    "sel_log_df = pd.read_csv('./data/preliminary_train/preliminary_sel_log_dataset.csv').drop_duplicates()\n",
    "# 读取训练标签数据：有重复数据！\n",
    "train_label1 = pd.read_csv('./data/preliminary_train/preliminary_train_label_dataset.csv')\n",
    "train_label2 = pd.read_csv('./data/preliminary_train/preliminary_train_label_dataset_s.csv')\n",
    "train_label_df = pd.concat([train_label1,train_label2],axis=0).drop_duplicates()\n",
    "# 读取词列表\n",
    "v1_word_list = list(pd.read_csv('./user_data/words/word_frequency_df.txt',sep='\\t')['word'])\n",
    "v1p1_word_list = list(pd.read_csv('./user_data/words/tags_incomplete.txt',sep='\\t',names=['word'])['word'])\n",
    "word_list = list(set(v1_word_list+v1p1_word_list))\n",
    "important_word_list = list(pd.read_csv('./user_data/words/important_word_df.csv')['word'])\n",
    "\n",
    "# 获取特征\n",
    "# 计算特征\n",
    "train_feature_df = caculateFeature(sel_log_df, train_label_df, important_word_list)\n",
    "# train_feature_df.to_csv('./user_data/feature_data/train_feature_df.csv', index=None)\n",
    "random.seed(0)\n",
    "val_mask = [random.random() < 0.3 for _ in range(len(train_feature_df))]\n",
    "train_mask = [not xx for xx in val_mask]\n",
    "temp_feature_df = train_feature_df[train_mask]\n",
    "val_feature_df = train_feature_df[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c253f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:37:09,853 13012 4092513637.py[line:469] - INFO: 开始第0轮训练和预测\n",
      "[23:37:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:13,217 13012 4092513637.py[line:476] - INFO: 第0轮训练和预测结束\n",
      "2022-05-14 23:37:13,238 13012 4092513637.py[line:469] - INFO: 开始第1轮训练和预测\n",
      "[23:37:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:16,532 13012 4092513637.py[line:476] - INFO: 第1轮训练和预测结束\n",
      "2022-05-14 23:37:16,554 13012 4092513637.py[line:469] - INFO: 开始第2轮训练和预测\n",
      "[23:37:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:19,855 13012 4092513637.py[line:476] - INFO: 第2轮训练和预测结束\n",
      "2022-05-14 23:37:19,877 13012 4092513637.py[line:469] - INFO: 开始第3轮训练和预测\n",
      "[23:37:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:23,175 13012 4092513637.py[line:476] - INFO: 第3轮训练和预测结束\n",
      "2022-05-14 23:37:23,197 13012 4092513637.py[line:469] - INFO: 开始第4轮训练和预测\n",
      "[23:37:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:26,452 13012 4092513637.py[line:476] - INFO: 第4轮训练和预测结束\n",
      "2022-05-14 23:37:26,475 13012 4092513637.py[line:469] - INFO: 开始第5轮训练和预测\n",
      "[23:37:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:29,838 13012 4092513637.py[line:476] - INFO: 第5轮训练和预测结束\n",
      "2022-05-14 23:37:29,860 13012 4092513637.py[line:469] - INFO: 开始第6轮训练和预测\n",
      "[23:37:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:33,160 13012 4092513637.py[line:476] - INFO: 第6轮训练和预测结束\n",
      "2022-05-14 23:37:33,182 13012 4092513637.py[line:469] - INFO: 开始第7轮训练和预测\n",
      "[23:37:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:36,595 13012 4092513637.py[line:476] - INFO: 第7轮训练和预测结束\n",
      "2022-05-14 23:37:36,618 13012 4092513637.py[line:469] - INFO: 开始第8轮训练和预测\n",
      "[23:37:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:39,999 13012 4092513637.py[line:476] - INFO: 第8轮训练和预测结束\n",
      "2022-05-14 23:37:40,021 13012 4092513637.py[line:469] - INFO: 开始第9轮训练和预测\n",
      "[23:37:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:43,278 13012 4092513637.py[line:476] - INFO: 第9轮训练和预测结束\n",
      "2022-05-14 23:37:43,299 13012 4092513637.py[line:469] - INFO: 开始第10轮训练和预测\n",
      "[23:37:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:37:46,623 13012 4092513637.py[line:476] - INFO: 第10轮训练和预测结束\n",
      "2022-05-14 23:37:46,644 13012 4092513637.py[line:469] - INFO: 开始第11轮训练和预测\n",
      "[23:37:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:49,971 13012 4092513637.py[line:476] - INFO: 第11轮训练和预测结束\n",
      "2022-05-14 23:37:49,992 13012 4092513637.py[line:469] - INFO: 开始第12轮训练和预测\n",
      "[23:37:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:53,244 13012 4092513637.py[line:476] - INFO: 第12轮训练和预测结束\n",
      "2022-05-14 23:37:53,267 13012 4092513637.py[line:469] - INFO: 开始第13轮训练和预测\n",
      "[23:37:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:56,595 13012 4092513637.py[line:476] - INFO: 第13轮训练和预测结束\n",
      "2022-05-14 23:37:56,618 13012 4092513637.py[line:469] - INFO: 开始第14轮训练和预测\n",
      "[23:37:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:37:59,981 13012 4092513637.py[line:476] - INFO: 第14轮训练和预测结束\n",
      "2022-05-14 23:38:00,004 13012 4092513637.py[line:469] - INFO: 开始第15轮训练和预测\n",
      "[23:38:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:03,395 13012 4092513637.py[line:476] - INFO: 第15轮训练和预测结束\n",
      "2022-05-14 23:38:03,417 13012 4092513637.py[line:469] - INFO: 开始第16轮训练和预测\n",
      "[23:38:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:06,745 13012 4092513637.py[line:476] - INFO: 第16轮训练和预测结束\n",
      "2022-05-14 23:38:06,768 13012 4092513637.py[line:469] - INFO: 开始第17轮训练和预测\n",
      "[23:38:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:10,156 13012 4092513637.py[line:476] - INFO: 第17轮训练和预测结束\n",
      "2022-05-14 23:38:10,180 13012 4092513637.py[line:469] - INFO: 开始第18轮训练和预测\n",
      "[23:38:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:13,418 13012 4092513637.py[line:476] - INFO: 第18轮训练和预测结束\n",
      "2022-05-14 23:38:13,439 13012 4092513637.py[line:469] - INFO: 开始第19轮训练和预测\n",
      "[23:38:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:16,651 13012 4092513637.py[line:476] - INFO: 第19轮训练和预测结束\n",
      "2022-05-14 23:38:16,682 13012 4092513637.py[line:469] - INFO: 开始第20轮训练和预测\n",
      "[23:38:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:19,844 13012 4092513637.py[line:476] - INFO: 第20轮训练和预测结束\n",
      "2022-05-14 23:38:19,866 13012 4092513637.py[line:469] - INFO: 开始第21轮训练和预测\n",
      "[23:38:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:38:23,149 13012 4092513637.py[line:476] - INFO: 第21轮训练和预测结束\n",
      "2022-05-14 23:38:23,171 13012 4092513637.py[line:469] - INFO: 开始第22轮训练和预测\n",
      "[23:38:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:26,466 13012 4092513637.py[line:476] - INFO: 第22轮训练和预测结束\n",
      "2022-05-14 23:38:26,487 13012 4092513637.py[line:469] - INFO: 开始第23轮训练和预测\n",
      "[23:38:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:29,759 13012 4092513637.py[line:476] - INFO: 第23轮训练和预测结束\n",
      "2022-05-14 23:38:29,780 13012 4092513637.py[line:469] - INFO: 开始第24轮训练和预测\n",
      "[23:38:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:33,105 13012 4092513637.py[line:476] - INFO: 第24轮训练和预测结束\n",
      "2022-05-14 23:38:33,125 13012 4092513637.py[line:469] - INFO: 开始第25轮训练和预测\n",
      "[23:38:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:36,390 13012 4092513637.py[line:476] - INFO: 第25轮训练和预测结束\n",
      "2022-05-14 23:38:36,420 13012 4092513637.py[line:469] - INFO: 开始第26轮训练和预测\n",
      "[23:38:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:39,730 13012 4092513637.py[line:476] - INFO: 第26轮训练和预测结束\n",
      "2022-05-14 23:38:39,752 13012 4092513637.py[line:469] - INFO: 开始第27轮训练和预测\n",
      "[23:38:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:43,105 13012 4092513637.py[line:476] - INFO: 第27轮训练和预测结束\n",
      "2022-05-14 23:38:43,125 13012 4092513637.py[line:469] - INFO: 开始第28轮训练和预测\n",
      "[23:38:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:46,492 13012 4092513637.py[line:476] - INFO: 第28轮训练和预测结束\n",
      "2022-05-14 23:38:46,522 13012 4092513637.py[line:469] - INFO: 开始第29轮训练和预测\n",
      "[23:38:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:49,797 13012 4092513637.py[line:476] - INFO: 第29轮训练和预测结束\n",
      "2022-05-14 23:38:49,819 13012 4092513637.py[line:469] - INFO: 开始第30轮训练和预测\n",
      "[23:38:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:53,112 13012 4092513637.py[line:476] - INFO: 第30轮训练和预测结束\n",
      "2022-05-14 23:38:53,134 13012 4092513637.py[line:469] - INFO: 开始第31轮训练和预测\n",
      "[23:38:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:38:56,385 13012 4092513637.py[line:476] - INFO: 第31轮训练和预测结束\n",
      "2022-05-14 23:38:56,405 13012 4092513637.py[line:469] - INFO: 开始第32轮训练和预测\n",
      "[23:38:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:38:59,671 13012 4092513637.py[line:476] - INFO: 第32轮训练和预测结束\n",
      "2022-05-14 23:38:59,692 13012 4092513637.py[line:469] - INFO: 开始第33轮训练和预测\n",
      "[23:38:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:03,036 13012 4092513637.py[line:476] - INFO: 第33轮训练和预测结束\n",
      "2022-05-14 23:39:03,056 13012 4092513637.py[line:469] - INFO: 开始第34轮训练和预测\n",
      "[23:39:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:06,321 13012 4092513637.py[line:476] - INFO: 第34轮训练和预测结束\n",
      "2022-05-14 23:39:06,343 13012 4092513637.py[line:469] - INFO: 开始第35轮训练和预测\n",
      "[23:39:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:09,721 13012 4092513637.py[line:476] - INFO: 第35轮训练和预测结束\n",
      "2022-05-14 23:39:09,744 13012 4092513637.py[line:469] - INFO: 开始第36轮训练和预测\n",
      "[23:39:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:13,038 13012 4092513637.py[line:476] - INFO: 第36轮训练和预测结束\n",
      "2022-05-14 23:39:13,059 13012 4092513637.py[line:469] - INFO: 开始第37轮训练和预测\n",
      "[23:39:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:16,418 13012 4092513637.py[line:476] - INFO: 第37轮训练和预测结束\n",
      "2022-05-14 23:39:16,440 13012 4092513637.py[line:469] - INFO: 开始第38轮训练和预测\n",
      "[23:39:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:19,764 13012 4092513637.py[line:476] - INFO: 第38轮训练和预测结束\n",
      "2022-05-14 23:39:19,787 13012 4092513637.py[line:469] - INFO: 开始第39轮训练和预测\n",
      "[23:39:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:23,105 13012 4092513637.py[line:476] - INFO: 第39轮训练和预测结束\n",
      "2022-05-14 23:39:23,127 13012 4092513637.py[line:469] - INFO: 开始第40轮训练和预测\n",
      "[23:39:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:26,336 13012 4092513637.py[line:476] - INFO: 第40轮训练和预测结束\n",
      "2022-05-14 23:39:26,357 13012 4092513637.py[line:469] - INFO: 开始第41轮训练和预测\n",
      "[23:39:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:29,724 13012 4092513637.py[line:476] - INFO: 第41轮训练和预测结束\n",
      "2022-05-14 23:39:29,746 13012 4092513637.py[line:469] - INFO: 开始第42轮训练和预测\n",
      "[23:39:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:33,110 13012 4092513637.py[line:476] - INFO: 第42轮训练和预测结束\n",
      "2022-05-14 23:39:33,130 13012 4092513637.py[line:469] - INFO: 开始第43轮训练和预测\n",
      "[23:39:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:39:36,398 13012 4092513637.py[line:476] - INFO: 第43轮训练和预测结束\n",
      "2022-05-14 23:39:36,420 13012 4092513637.py[line:469] - INFO: 开始第44轮训练和预测\n",
      "[23:39:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:39,638 13012 4092513637.py[line:476] - INFO: 第44轮训练和预测结束\n",
      "2022-05-14 23:39:39,659 13012 4092513637.py[line:469] - INFO: 开始第45轮训练和预测\n",
      "[23:39:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:42,908 13012 4092513637.py[line:476] - INFO: 第45轮训练和预测结束\n",
      "2022-05-14 23:39:42,928 13012 4092513637.py[line:469] - INFO: 开始第46轮训练和预测\n",
      "[23:39:42] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:46,156 13012 4092513637.py[line:476] - INFO: 第46轮训练和预测结束\n",
      "2022-05-14 23:39:46,182 13012 4092513637.py[line:469] - INFO: 开始第47轮训练和预测\n",
      "[23:39:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:49,463 13012 4092513637.py[line:476] - INFO: 第47轮训练和预测结束\n",
      "2022-05-14 23:39:49,484 13012 4092513637.py[line:469] - INFO: 开始第48轮训练和预测\n",
      "[23:39:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:52,706 13012 4092513637.py[line:476] - INFO: 第48轮训练和预测结束\n",
      "2022-05-14 23:39:52,727 13012 4092513637.py[line:469] - INFO: 开始第49轮训练和预测\n",
      "[23:39:52] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:56,067 13012 4092513637.py[line:476] - INFO: 第49轮训练和预测结束\n",
      "2022-05-14 23:39:56,087 13012 4092513637.py[line:469] - INFO: 开始第50轮训练和预测\n",
      "[23:39:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:39:59,577 13012 4092513637.py[line:476] - INFO: 第50轮训练和预测结束\n",
      "2022-05-14 23:39:59,599 13012 4092513637.py[line:469] - INFO: 开始第51轮训练和预测\n",
      "[23:39:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:03,032 13012 4092513637.py[line:476] - INFO: 第51轮训练和预测结束\n",
      "2022-05-14 23:40:03,055 13012 4092513637.py[line:469] - INFO: 开始第52轮训练和预测\n",
      "[23:40:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:06,499 13012 4092513637.py[line:476] - INFO: 第52轮训练和预测结束\n",
      "2022-05-14 23:40:06,521 13012 4092513637.py[line:469] - INFO: 开始第53轮训练和预测\n",
      "[23:40:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:09,847 13012 4092513637.py[line:476] - INFO: 第53轮训练和预测结束\n",
      "2022-05-14 23:40:09,869 13012 4092513637.py[line:469] - INFO: 开始第54轮训练和预测\n",
      "[23:40:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:40:13,159 13012 4092513637.py[line:476] - INFO: 第54轮训练和预测结束\n",
      "2022-05-14 23:40:13,181 13012 4092513637.py[line:469] - INFO: 开始第55轮训练和预测\n",
      "[23:40:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:16,526 13012 4092513637.py[line:476] - INFO: 第55轮训练和预测结束\n",
      "2022-05-14 23:40:16,547 13012 4092513637.py[line:469] - INFO: 开始第56轮训练和预测\n",
      "[23:40:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:19,959 13012 4092513637.py[line:476] - INFO: 第56轮训练和预测结束\n",
      "2022-05-14 23:40:19,981 13012 4092513637.py[line:469] - INFO: 开始第57轮训练和预测\n",
      "[23:40:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:23,250 13012 4092513637.py[line:476] - INFO: 第57轮训练和预测结束\n",
      "2022-05-14 23:40:23,271 13012 4092513637.py[line:469] - INFO: 开始第58轮训练和预测\n",
      "[23:40:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:26,715 13012 4092513637.py[line:476] - INFO: 第58轮训练和预测结束\n",
      "2022-05-14 23:40:26,737 13012 4092513637.py[line:469] - INFO: 开始第59轮训练和预测\n",
      "[23:40:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:30,311 13012 4092513637.py[line:476] - INFO: 第59轮训练和预测结束\n",
      "2022-05-14 23:40:30,336 13012 4092513637.py[line:469] - INFO: 开始第60轮训练和预测\n",
      "[23:40:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:33,910 13012 4092513637.py[line:476] - INFO: 第60轮训练和预测结束\n",
      "2022-05-14 23:40:33,933 13012 4092513637.py[line:469] - INFO: 开始第61轮训练和预测\n",
      "[23:40:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:37,448 13012 4092513637.py[line:476] - INFO: 第61轮训练和预测结束\n",
      "2022-05-14 23:40:37,470 13012 4092513637.py[line:469] - INFO: 开始第62轮训练和预测\n",
      "[23:40:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:41,033 13012 4092513637.py[line:476] - INFO: 第62轮训练和预测结束\n",
      "2022-05-14 23:40:41,054 13012 4092513637.py[line:469] - INFO: 开始第63轮训练和预测\n",
      "[23:40:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:44,619 13012 4092513637.py[line:476] - INFO: 第63轮训练和预测结束\n",
      "2022-05-14 23:40:44,641 13012 4092513637.py[line:469] - INFO: 开始第64轮训练和预测\n",
      "[23:40:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:48,224 13012 4092513637.py[line:476] - INFO: 第64轮训练和预测结束\n",
      "2022-05-14 23:40:48,247 13012 4092513637.py[line:469] - INFO: 开始第65轮训练和预测\n",
      "[23:40:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:40:51,819 13012 4092513637.py[line:476] - INFO: 第65轮训练和预测结束\n",
      "2022-05-14 23:40:51,842 13012 4092513637.py[line:469] - INFO: 开始第66轮训练和预测\n",
      "[23:40:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:55,616 13012 4092513637.py[line:476] - INFO: 第66轮训练和预测结束\n",
      "2022-05-14 23:40:55,639 13012 4092513637.py[line:469] - INFO: 开始第67轮训练和预测\n",
      "[23:40:55] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:55] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:40:59,220 13012 4092513637.py[line:476] - INFO: 第67轮训练和预测结束\n",
      "2022-05-14 23:40:59,242 13012 4092513637.py[line:469] - INFO: 开始第68轮训练和预测\n",
      "[23:40:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:02,818 13012 4092513637.py[line:476] - INFO: 第68轮训练和预测结束\n",
      "2022-05-14 23:41:02,841 13012 4092513637.py[line:469] - INFO: 开始第69轮训练和预测\n",
      "[23:41:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:06,470 13012 4092513637.py[line:476] - INFO: 第69轮训练和预测结束\n",
      "2022-05-14 23:41:06,492 13012 4092513637.py[line:469] - INFO: 开始第70轮训练和预测\n",
      "[23:41:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:10,005 13012 4092513637.py[line:476] - INFO: 第70轮训练和预测结束\n",
      "2022-05-14 23:41:10,027 13012 4092513637.py[line:469] - INFO: 开始第71轮训练和预测\n",
      "[23:41:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:13,606 13012 4092513637.py[line:476] - INFO: 第71轮训练和预测结束\n",
      "2022-05-14 23:41:13,628 13012 4092513637.py[line:469] - INFO: 开始第72轮训练和预测\n",
      "[23:41:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:17,213 13012 4092513637.py[line:476] - INFO: 第72轮训练和预测结束\n",
      "2022-05-14 23:41:17,235 13012 4092513637.py[line:469] - INFO: 开始第73轮训练和预测\n",
      "[23:41:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:20,934 13012 4092513637.py[line:476] - INFO: 第73轮训练和预测结束\n",
      "2022-05-14 23:41:20,956 13012 4092513637.py[line:469] - INFO: 开始第74轮训练和预测\n",
      "[23:41:20] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:24,616 13012 4092513637.py[line:476] - INFO: 第74轮训练和预测结束\n",
      "2022-05-14 23:41:24,639 13012 4092513637.py[line:469] - INFO: 开始第75轮训练和预测\n",
      "[23:41:24] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:28,218 13012 4092513637.py[line:476] - INFO: 第75轮训练和预测结束\n",
      "2022-05-14 23:41:28,240 13012 4092513637.py[line:469] - INFO: 开始第76轮训练和预测\n",
      "[23:41:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:41:31,935 13012 4092513637.py[line:476] - INFO: 第76轮训练和预测结束\n",
      "2022-05-14 23:41:31,958 13012 4092513637.py[line:469] - INFO: 开始第77轮训练和预测\n",
      "[23:41:31] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:35,590 13012 4092513637.py[line:476] - INFO: 第77轮训练和预测结束\n",
      "2022-05-14 23:41:35,613 13012 4092513637.py[line:469] - INFO: 开始第78轮训练和预测\n",
      "[23:41:35] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:39,240 13012 4092513637.py[line:476] - INFO: 第78轮训练和预测结束\n",
      "2022-05-14 23:41:39,263 13012 4092513637.py[line:469] - INFO: 开始第79轮训练和预测\n",
      "[23:41:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:42,884 13012 4092513637.py[line:476] - INFO: 第79轮训练和预测结束\n",
      "2022-05-14 23:41:42,907 13012 4092513637.py[line:469] - INFO: 开始第80轮训练和预测\n",
      "[23:41:42] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:46,540 13012 4092513637.py[line:476] - INFO: 第80轮训练和预测结束\n",
      "2022-05-14 23:41:46,562 13012 4092513637.py[line:469] - INFO: 开始第81轮训练和预测\n",
      "[23:41:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:50,144 13012 4092513637.py[line:476] - INFO: 第81轮训练和预测结束\n",
      "2022-05-14 23:41:50,166 13012 4092513637.py[line:469] - INFO: 开始第82轮训练和预测\n",
      "[23:41:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:53,722 13012 4092513637.py[line:476] - INFO: 第82轮训练和预测结束\n",
      "2022-05-14 23:41:53,745 13012 4092513637.py[line:469] - INFO: 开始第83轮训练和预测\n",
      "[23:41:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:41:57,318 13012 4092513637.py[line:476] - INFO: 第83轮训练和预测结束\n",
      "2022-05-14 23:41:57,340 13012 4092513637.py[line:469] - INFO: 开始第84轮训练和预测\n",
      "[23:41:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:41:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:00,992 13012 4092513637.py[line:476] - INFO: 第84轮训练和预测结束\n",
      "2022-05-14 23:42:01,014 13012 4092513637.py[line:469] - INFO: 开始第85轮训练和预测\n",
      "[23:42:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:04,577 13012 4092513637.py[line:476] - INFO: 第85轮训练和预测结束\n",
      "2022-05-14 23:42:04,599 13012 4092513637.py[line:469] - INFO: 开始第86轮训练和预测\n",
      "[23:42:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:08,121 13012 4092513637.py[line:476] - INFO: 第86轮训练和预测结束\n",
      "2022-05-14 23:42:08,143 13012 4092513637.py[line:469] - INFO: 开始第87轮训练和预测\n",
      "[23:42:08] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:42:11,724 13012 4092513637.py[line:476] - INFO: 第87轮训练和预测结束\n",
      "2022-05-14 23:42:11,746 13012 4092513637.py[line:469] - INFO: 开始第88轮训练和预测\n",
      "[23:42:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:15,350 13012 4092513637.py[line:476] - INFO: 第88轮训练和预测结束\n",
      "2022-05-14 23:42:15,372 13012 4092513637.py[line:469] - INFO: 开始第89轮训练和预测\n",
      "[23:42:15] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:18,930 13012 4092513637.py[line:476] - INFO: 第89轮训练和预测结束\n",
      "2022-05-14 23:42:18,952 13012 4092513637.py[line:469] - INFO: 开始第90轮训练和预测\n",
      "[23:42:18] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:22,459 13012 4092513637.py[line:476] - INFO: 第90轮训练和预测结束\n",
      "2022-05-14 23:42:22,488 13012 4092513637.py[line:469] - INFO: 开始第91轮训练和预测\n",
      "[23:42:22] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:26,139 13012 4092513637.py[line:476] - INFO: 第91轮训练和预测结束\n",
      "2022-05-14 23:42:26,161 13012 4092513637.py[line:469] - INFO: 开始第92轮训练和预测\n",
      "[23:42:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:29,768 13012 4092513637.py[line:476] - INFO: 第92轮训练和预测结束\n",
      "2022-05-14 23:42:29,789 13012 4092513637.py[line:469] - INFO: 开始第93轮训练和预测\n",
      "[23:42:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:33,343 13012 4092513637.py[line:476] - INFO: 第93轮训练和预测结束\n",
      "2022-05-14 23:42:33,363 13012 4092513637.py[line:469] - INFO: 开始第94轮训练和预测\n",
      "[23:42:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:36,907 13012 4092513637.py[line:476] - INFO: 第94轮训练和预测结束\n",
      "2022-05-14 23:42:36,927 13012 4092513637.py[line:469] - INFO: 开始第95轮训练和预测\n",
      "[23:42:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:40,250 13012 4092513637.py[line:476] - INFO: 第95轮训练和预测结束\n",
      "2022-05-14 23:42:40,270 13012 4092513637.py[line:469] - INFO: 开始第96轮训练和预测\n",
      "[23:42:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:43,495 13012 4092513637.py[line:476] - INFO: 第96轮训练和预测结束\n",
      "2022-05-14 23:42:43,516 13012 4092513637.py[line:469] - INFO: 开始第97轮训练和预测\n",
      "[23:42:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:46,702 13012 4092513637.py[line:476] - INFO: 第97轮训练和预测结束\n",
      "2022-05-14 23:42:46,724 13012 4092513637.py[line:469] - INFO: 开始第98轮训练和预测\n",
      "[23:42:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-14 23:42:49,920 13012 4092513637.py[line:476] - INFO: 第98轮训练和预测结束\n",
      "2022-05-14 23:42:49,940 13012 4092513637.py[line:469] - INFO: 开始第99轮训练和预测\n",
      "[23:42:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:42:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-14 23:42:53,225 13012 4092513637.py[line:476] - INFO: 第99轮训练和预测结束\n",
      "2022-05-14 23:42:53,264 13012 4092513637.py[line:482] - INFO: 训练集评估效果: \n",
      "2022-05-14 23:42:53,273 13012 4092513637.py[line:369] - INFO: Label 0:   Precision  0.47, Recall  0.60, F1  0.53\n",
      "2022-05-14 23:42:53,275 13012 4092513637.py[line:369] - INFO: Label 1:   Precision  0.77, Recall  0.69, F1  0.73\n",
      "2022-05-14 23:42:53,278 13012 4092513637.py[line:369] - INFO: Label 2:   Precision  0.97, Recall  0.94, F1  0.95\n",
      "2022-05-14 23:42:53,280 13012 4092513637.py[line:369] - INFO: Label 3:   Precision  0.88, Recall  0.95, F1  0.91\n",
      "2022-05-14 23:42:53,280 13012 4092513637.py[line:370] - INFO: macro_f1: 0.6745257012142057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgb训练预测\n",
    "# 使用报错时间\n",
    "# 100 500 0.6303\n",
    "# 50 700 0.6261\n",
    "# 使用最近邻时间\n",
    "\n",
    "predictions = xgbRandomTrainPredict(temp_feature_df, val_feature_df, val_feature_df[['sn', 'fault_time', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f219e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 01:45:40,780 15968 3915516630.py[line:34] - INFO: 开始第0轮训练和预测\n",
      "[01:45:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:45:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:45:46,567 15968 3915516630.py[line:41] - INFO: 第0轮训练和预测结束\n",
      "2022-05-13 01:45:46,590 15968 3915516630.py[line:34] - INFO: 开始第1轮训练和预测\n",
      "[01:45:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:45:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m sub_train_data \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(sub_train_feature,label \u001b[38;5;241m=\u001b[39m sub_train_label)\n\u001b[0;32m     34\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m开始第\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m轮训练和预测\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28miter\u001b[39m))\n\u001b[1;32m---> 35\u001b[0m sub_xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m sub_test_pred \u001b[38;5;241m=\u001b[39m sub_xgb_model\u001b[38;5;241m.\u001b[39mpredict(test_feature)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_feature_df = temp_feature_df\n",
    "test_feature_df = val_feature_df\n",
    "label_df = val_feature_df[['sn', 'fault_time', 'label']]\n",
    "\n",
    "\n",
    "## 每个子模型样本均衡，利用投票规则生成最终预测\n",
    "random.seed(0)\n",
    "N = 100 # number of the models\n",
    "num_sample = 500 # number of samples for each label\n",
    "train_feature_df\n",
    "\n",
    "\n",
    "_label0_index_list = list(train_feature_df[train_feature_df['label'] == 0].index)\n",
    "_label1_index_list = list(train_feature_df[train_feature_df['label'] == 1].index)\n",
    "_label2_index_list = list(train_feature_df[train_feature_df['label'] == 2].index)\n",
    "_label3_index_list = list(train_feature_df[train_feature_df['label'] == 3].index)\n",
    "feature_name_list = list(train_feature_df.columns)[0:-3]\n",
    "test_feature = np.array(test_feature_df[feature_name_list])\n",
    "test_feature = xgb.DMatrix(test_feature)\n",
    "prediction_df = test_feature_df[['sn', 'fault_time']]\n",
    "\n",
    "for iter in np.arange(N):\n",
    "    idx_0 = random.sample(_label0_index_list, num_sample)\n",
    "    idx_1 = random.sample(_label1_index_list, num_sample)\n",
    "    idx_2 = random.sample(_label2_index_list, num_sample)\n",
    "    idx_3 = random.sample(_label3_index_list, num_sample)\n",
    "    idx = np.hstack((idx_0, idx_1, idx_2, idx_3))\n",
    "    random.shuffle(idx)\n",
    "    sub_train_feature_df = train_feature_df.loc[idx, :]\n",
    "    sub_train_feature = np.array(sub_train_feature_df[feature_name_list])\n",
    "    sub_train_label = np.array(sub_train_feature_df['label'])\n",
    "    sub_train_data = xgb.DMatrix(sub_train_feature,label = sub_train_label)\n",
    "\n",
    "    logger.info('开始第{}轮训练和预测'.format(iter))\n",
    "    sub_xgb_model = xgb.train(xgb_params, sub_train_data, num_boost_round=500)\n",
    "    sub_test_pred = sub_xgb_model.predict(test_feature)\n",
    "    if iter == 0:\n",
    "        val_pred = sub_test_pred\n",
    "    else:\n",
    "        val_pred = np.vstack((val_pred, sub_test_pred))\n",
    "    logger.info('第{}轮训练和预测结束'.format(iter))\n",
    "\n",
    "# 训练集指标评估\n",
    "final_pred = [np.argmax(np.bincount(val_pred[:, i].astype(int))) for i in np.arange(val_pred.shape[1])]\n",
    "final_pred = np.array(final_pred).astype(int)\n",
    "prediction_df['label'] = final_pred\n",
    "logger.info('训练集评估效果: ')\n",
    "macro_f1(label_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0105e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     4,     5,     6,     7,     8,     9,\n",
       "               10,\n",
       "            ...\n",
       "            16593, 16594, 16595, 16596, 16597, 16598, 16599, 16600, 16601,\n",
       "            16603],\n",
       "           dtype='int64', length=11617)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_df.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Log_diagosis_python",
   "language": "python",
   "name": "log_diagosis_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
