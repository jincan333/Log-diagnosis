{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ac94bf",
   "metadata": {},
   "source": [
    "# 词汇仅使用重要性进入V2前300的 + 100轮随机训练和预测投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d587f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from logging import handlers\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import traceback\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "## 日志格式设置\n",
    "# 日志级别关系映射\n",
    "level_relations = {\n",
    "    'debug': logging.DEBUG,\n",
    "    'info': logging.INFO,\n",
    "    'warning': logging.WARNING,\n",
    "    'error': logging.ERROR,\n",
    "    'crit': logging.CRITICAL\n",
    "}\n",
    "def get_logger(filename, level='info'):\n",
    "    # 创建日志对象\n",
    "    log = logging.getLogger(filename)\n",
    "    # 设置日志级别\n",
    "    log.setLevel(level_relations.get(level))\n",
    "    # 日志输出格式\n",
    "    fmt = logging.Formatter('%(asctime)s %(thread)d %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "    # 输出到控制台\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(fmt)\n",
    "    # 输出到文件\n",
    "    # 日志文件按天进行保存，每天一个日志文件\n",
    "    file_handler = handlers.TimedRotatingFileHandler(filename=filename, when='D', backupCount=1, encoding='utf-8')\n",
    "    # 按照大小自动分割日志文件，一旦达到指定的大小重新生成文件\n",
    "    # file_handler = handlers.RotatingFileHandler(filename=filename, maxBytes=1*1024*1024*1024, backupCount=1, encoding='utf-8')\n",
    "    file_handler.setFormatter(fmt)\n",
    "    if not log.handlers:\n",
    "        log.addHandler(console_handler)\n",
    "        log.addHandler(file_handler)\n",
    "    return log\n",
    "\n",
    "# sn分组后，本次报错和上次报错之间的日志匹配到本次报错\n",
    "def divideLogByFaultTime(log_label_df: pd.DataFrame):\n",
    "    log_correspond_label_df = pd.DataFrame(columns=['sn', 'fault_time', 'msg', 'time', 'server_model', 'label'])\n",
    "    no_label_log_list = []\n",
    "    log_label_df = log_label_df.reset_index(drop=True)\n",
    "\n",
    "    for sn, log in log_label_df.groupby('sn'):\n",
    "        if len(log[log['label'] != '']) == 0:\n",
    "            no_label_log_list.append(log)\n",
    "        elif len(log[log['label'] != '']) == 1:\n",
    "            msg_df = log[log['label'] == '']\n",
    "            msg_df['label'] = log[log['label'] != '']['label'].iloc[0]\n",
    "            msg_df['fault_time'] = log[log['label'] != '']['time'].iloc[0]\n",
    "            log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "        else:\n",
    "            # 使用index的顺序取数时，要注意index必须按所需的顺序排列\n",
    "            cutoff_index = [-1] + log.loc[log['label'] != ''].index.tolist() + [log.index.tolist()[-1] + 1]\n",
    "            for kth in range(len(cutoff_index) - 1):\n",
    "                temp_log = log.loc[(log.index <= cutoff_index[kth + 1]) & (log.index > cutoff_index[kth])]\n",
    "                if len(temp_log) > 0:\n",
    "                    if len(temp_log[temp_log['label'] != '']) == 0:\n",
    "                        no_label_log_list.append(temp_log)\n",
    "                    # 只有标签，没有日志的数据，把标签的部分数据直接作为日志\n",
    "                    elif len(temp_log) == 1:\n",
    "                        msg_df = temp_log\n",
    "                        msg_df['fault_time'] = temp_log[temp_log['label'] != '']['time'].iloc[0]\n",
    "                        log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "                    else:\n",
    "                        msg_df = temp_log[temp_log['label'] == '']\n",
    "                        msg_df['label'] = temp_log[temp_log['label'] != '']['label'].iloc[0]\n",
    "                        msg_df['fault_time'] = temp_log[temp_log['label'] != '']['time'].iloc[0]\n",
    "                        log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "    return log_correspond_label_df, no_label_log_list\n",
    "\n",
    "# 计算统计特征\n",
    "def calculateStatisticFeature(log_correspond_label_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    use_log_label_df = log_correspond_label_df\n",
    "\n",
    "    use_log_label_df['msg_hour'] = use_log_label_df['time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    use_log_label_df['msg_minute'] = use_log_label_df['time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").minute)\n",
    "    use_log_label_df['fault_hour'] = use_log_label_df['fault_time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    use_log_label_df['fault_minute'] = use_log_label_df['fault_time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").minute)\n",
    "\n",
    "    # 0408新增\n",
    "    # 最近一次日志时间距报错时间间隔，单位秒\n",
    "    nearest_msg_fault_time_delta_list = []\n",
    "    # 日志不去重时长度1,2,3,4日志数量统计\n",
    "    all_msg_1_cnt_list = []\n",
    "    all_msg_2_cnt_list = []\n",
    "    all_msg_3_cnt_list = []\n",
    "    all_msg_4_cnt_list = []\n",
    "\n",
    "    fault_minute_list = []\n",
    "    msg_1_cnt_list = []\n",
    "    msg_2_cnt_list = []\n",
    "    msg_3_cnt_list = []\n",
    "    msg_4_cnt_list = []\n",
    "    msg_hour_max_list = []\n",
    "    msg_hour_min_list = []\n",
    "    msg_hour_avg_list = []\n",
    "    msg_hour_median_list = []\n",
    "    msg_hour_mode_list = []\n",
    "    msg_minute_max_list = []\n",
    "    msg_minute_min_list = []\n",
    "    msg_minute_avg_list = []\n",
    "    msg_minute_median_list = []\n",
    "    msg_minute_mode_list = []\n",
    "\n",
    "    sn_list = []\n",
    "    server_model_list = []\n",
    "    msg_log_list = []\n",
    "    msg_cnt_list = []\n",
    "    fault_hour_list = []\n",
    "    label_list = []\n",
    "    fault_time_list = []\n",
    "    for msg_log_df in use_log_label_df.groupby(['sn', 'fault_time', 'label']):\n",
    "        msg_log_str = ''\n",
    "        all_msg_1_cnt = 0\n",
    "        all_msg_2_cnt = 0\n",
    "        all_msg_3_cnt = 0\n",
    "        all_msg_4_cnt = 0\n",
    "        msg_1_cnt = 0\n",
    "        msg_2_cnt = 0\n",
    "        msg_3_cnt = 0\n",
    "        msg_4_cnt = 0\n",
    "        for info in msg_log_df[1]['msg']:\n",
    "            if info == info:\n",
    "                if len(info.split('|')) == 1:\n",
    "                    all_msg_1_cnt += 1\n",
    "                elif len(info.split('|')) == 2:\n",
    "                    all_msg_2_cnt += 1\n",
    "                elif len(info.split('|')) == 3:\n",
    "                    all_msg_3_cnt += 1\n",
    "                else:\n",
    "                    all_msg_4_cnt += 1\n",
    "        for info in msg_log_df[1]['msg'].drop_duplicates():\n",
    "            if info == info:\n",
    "                msg_log_str = msg_log_str + info.lower() + '.'\n",
    "                if len(info.split('|')) == 1:\n",
    "                    msg_1_cnt += 1\n",
    "                elif len(info.split('|')) == 2:\n",
    "                    msg_2_cnt += 1\n",
    "                elif len(info.split('|')) == 3:\n",
    "                    msg_3_cnt += 1\n",
    "                else:\n",
    "                    msg_4_cnt += 1\n",
    "        nearest_msg_fault_time_delta = abs(datetime.strptime(msg_log_df[1].iloc[-1]['time'], '%Y-%m-%d %H:%M:%S'\n",
    "                                                             ) - datetime.strptime(msg_log_df[0][1],\n",
    "                                                                                   '%Y-%m-%d %H:%M:%S'))\n",
    "        nearest_msg_fault_time_delta = nearest_msg_fault_time_delta.days * 24 * 3600 + nearest_msg_fault_time_delta.seconds\n",
    "        sm = int(msg_log_df[1].iloc[0]['server_model'][2:])\n",
    "\n",
    "        sn_list.append(msg_log_df[0][0])\n",
    "        fault_time_list.append(msg_log_df[0][1])\n",
    "        label_list.append(msg_log_df[0][2])\n",
    "\n",
    "        nearest_msg_fault_time_delta_list.append(nearest_msg_fault_time_delta)\n",
    "        server_model_list.append(sm)\n",
    "        msg_log_list.append(msg_log_str)\n",
    "        msg_cnt_list.append(len(msg_log_df[1]))\n",
    "\n",
    "        fault_hour_list.append(msg_log_df[1].iloc[0]['fault_hour'])\n",
    "        fault_minute_list.append(msg_log_df[1].iloc[0]['fault_minute'])\n",
    "\n",
    "        all_msg_1_cnt_list.append(all_msg_1_cnt)\n",
    "        all_msg_2_cnt_list.append(all_msg_2_cnt)\n",
    "        all_msg_3_cnt_list.append(all_msg_3_cnt)\n",
    "        all_msg_4_cnt_list.append(all_msg_4_cnt)\n",
    "\n",
    "        msg_1_cnt_list.append(msg_1_cnt)\n",
    "        msg_2_cnt_list.append(msg_2_cnt)\n",
    "        msg_3_cnt_list.append(msg_3_cnt)\n",
    "        msg_4_cnt_list.append(msg_4_cnt)\n",
    "\n",
    "        msg_hour_max_list.append(msg_log_df[1]['msg_hour'].max())\n",
    "        msg_hour_min_list.append(msg_log_df[1]['msg_hour'].min())\n",
    "        msg_hour_avg_list.append(msg_log_df[1]['msg_hour'].mean())\n",
    "        msg_hour_median_list.append(msg_log_df[1]['msg_hour'].median())\n",
    "        msg_hour_mode_list.append(msg_log_df[1]['msg_hour'].mode()[0])\n",
    "\n",
    "        msg_minute_max_list.append(msg_log_df[1]['msg_minute'].max())\n",
    "        msg_minute_min_list.append(msg_log_df[1]['msg_minute'].min())\n",
    "        msg_minute_avg_list.append(msg_log_df[1]['msg_minute'].mean())\n",
    "        msg_minute_median_list.append(msg_log_df[1]['msg_minute'].median())\n",
    "        msg_minute_mode_list.append(msg_log_df[1]['msg_minute'].mode()[0])\n",
    "\n",
    "    msg_log_label_df = pd.DataFrame(\n",
    "        {\n",
    "            'sn': sn_list,\n",
    "            'fault_time': fault_time_list,\n",
    "            'server_model': server_model_list,\n",
    "            'msg_cnt': msg_cnt_list,\n",
    "            'fault_hour': fault_hour_list,\n",
    "            'fault_minute': fault_minute_list,\n",
    "            'nearest_msg_fault_time_delta': nearest_msg_fault_time_delta_list,\n",
    "            'all_msg_1_cnt': all_msg_1_cnt_list,\n",
    "            'all_msg_2_cnt': all_msg_2_cnt_list,\n",
    "            'all_msg_3_cnt': all_msg_3_cnt_list,\n",
    "            'all_msg_4_cnt': all_msg_4_cnt_list,\n",
    "            'msg_1_cnt': msg_1_cnt_list,\n",
    "            'msg_2_cnt': msg_2_cnt_list,\n",
    "            'msg_3_cnt': msg_3_cnt_list,\n",
    "            'msg_4_cnt': msg_4_cnt_list,\n",
    "            'msg_hour_max': msg_hour_max_list,\n",
    "            'msg_hour_min': msg_hour_min_list,\n",
    "            'msg_hour_avg': msg_hour_avg_list,\n",
    "            'msg_hour_median': msg_hour_median_list,\n",
    "            'msg_hour_mode': msg_hour_mode_list,\n",
    "            'msg_minute_max': msg_minute_max_list,\n",
    "            'msg_minute_min': msg_minute_min_list,\n",
    "            'msg_minute_avg': msg_minute_avg_list,\n",
    "            'msg_minute_median': msg_minute_median_list,\n",
    "            'msg_minute_mode': msg_minute_mode_list,\n",
    "            'msg_log': msg_log_list,\n",
    "            'label': label_list\n",
    "        }\n",
    "    )\n",
    "    return msg_log_label_df\n",
    "\n",
    "# 计算特征函数\n",
    "def caculateFeature(log_df: pd.DataFrame, label_df: pd.DataFrame, word_list: list) -> pd.DataFrame:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    logger.info('开始拼接日志和标签数据')\n",
    "    log_df['label'] = ''\n",
    "    label_df['time'] = label_df['fault_time']\n",
    "    label_df['msg'] = ''\n",
    "    label_df['server_model'] = label_df['sn'].map(dict(zip(log_df['sn'], log_df['server_model'])))\n",
    "    label_df = label_df[['sn', 'time', 'msg', 'server_model', 'label']]\n",
    "    log_label_df = pd.concat([log_df, label_df], axis=0).sort_values(by='time')\n",
    "    log_label_df['fault_time'] = ''\n",
    "    log_label_df = log_label_df[['sn', 'fault_time', 'msg', 'time', 'server_model', 'label']]\n",
    "    logger.info('拼接日志和标签数据结束')\n",
    "\n",
    "    logger.info('开始匹配日志和标签')\n",
    "    logger.info('使用报错时间截断进行划分')\n",
    "    # 使用报错时间截断进行划分\n",
    "    # FaultTime_log_correspond_label_df, FaultTime_no_label_log_list = divideLogByFaultTime(log_label_df)\n",
    "    # FaultTime_log_correspond_label_df.to_csv('./user_data/tmp_data/FaultTime_log_correspond_label_df.csv', index = None)\n",
    "    FaultTime_log_correspond_label_df = pd.read_csv('./user_data/tmp_data/FaultTime_log_correspond_label_df.csv')\n",
    "    logger.info('匹配日志和标签结束')\n",
    "\n",
    "    logger.info('开始计算统计特征')\n",
    "    # 使用报错时间截断进行划分\n",
    "    msg_log_label_df = calculateStatisticFeature(FaultTime_log_correspond_label_df)\n",
    "    logger.info('计算统计特征结束')\n",
    "\n",
    "    msg_log_list = list(msg_log_label_df['msg_log'])\n",
    "    label_list = list(msg_log_label_df['label'])\n",
    "\n",
    "    # 计算词频向量\n",
    "    logger.info('开始计算词频特征')\n",
    "    frequency_vector_list = []\n",
    "    tag = 0\n",
    "    for word in word_list:\n",
    "        if tag % 100 == 0:\n",
    "            print(tag, datetime.now())\n",
    "        pattern = re.compile(word)\n",
    "        frequency_vector = [len(re.findall(pattern, log)) for log in msg_log_list]\n",
    "        frequency_vector_list.append(frequency_vector)\n",
    "        tag += 1\n",
    "    logger.info('计算词频特征结束')\n",
    "\n",
    "    frequency_vector_df = pd.DataFrame(frequency_vector_list)\n",
    "    frequency_vector_df = frequency_vector_df.T\n",
    "    frequency_vector_df.columns = word_list\n",
    "    statistic_feature_list = list(msg_log_label_df.columns)[2:-2]\n",
    "    feature_df = frequency_vector_df\n",
    "    feature_df[statistic_feature_list] = msg_log_label_df[statistic_feature_list]\n",
    "\n",
    "    feature_df['label'] = label_list\n",
    "    feature_df[['sn', 'fault_time']] = msg_log_label_df[['sn', 'fault_time']]\n",
    "    logger.info('最后3列为: label, sn, fault_time, 其余列均为特征')\n",
    "    logger.info('数据条数: {}, 特征个数: {}'.format(feature_df.shape[0], feature_df.shape[1]-3))\n",
    "    return feature_df\n",
    "\n",
    "\n",
    "# xgb模型参数\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类问题\n",
    "    'num_class': 4,  # 类别数，与multi softmax并用\n",
    "    'gamma': 0.1,  # 用于控制是否后剪枝的参数，越大越保守，一般0.1 0.2的样子\n",
    "    'max_depth': 6,  # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,  # 控制模型复杂度的权重值的L2 正则化项参数，参数越大，模型越不容易过拟合\n",
    "    'subsample': 1,  # 随机采样训练样本\n",
    "    'colsample_bytree': 1,  # 这个参数默认为1，是每个叶子里面h的和至少是多少\n",
    "    # 对于正负样本不均衡时的0-1分类而言，假设h在0.01附近，min_child_weight为1\n",
    "    # 意味着叶子节点中最少需要包含100个样本。这个参数非常影响结果，\n",
    "    # 控制叶子节点中二阶导的和的最小值，该参数值越小，越容易过拟合\n",
    "    'silent': 0,  # 设置成1 则没有运行信息输入，最好是设置成0\n",
    "    'eta': 0.3,  # 如同学习率\n",
    "    'seed': 1000,\n",
    "    'nthread': 16,  # CPU线程数\n",
    "    # 'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "# 指标评估\n",
    "def macro_f1(label_df: pd.DataFrame, prediction_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param label_df: [sn,fault_time,label]\n",
    "    :param prediction_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    prediction_df.columns = ['sn', 'fault_time', 'prediction']\n",
    "    outcome_df = pd.merge(label_df, prediction_df ,how = 'left', on = ['sn', 'fault_time'])\n",
    "    weights = [5 / 11, 4 / 11, 1 / 11, 1 / 11]\n",
    "    macro_F1 = 0.\n",
    "    for i in range(len(weights)):\n",
    "        TP = len(outcome_df[(outcome_df['label'] == i) & (outcome_df['prediction'] == i)])\n",
    "        FP = len(outcome_df[(outcome_df['label'] != i) & (outcome_df['prediction'] == i)])\n",
    "        FN = len(outcome_df[(outcome_df['label'] == i) & (outcome_df['prediction'] != i)])\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        F1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        macro_F1 += weights[i] * F1\n",
    "        logger.info('Label {}:   Precision {: .2f}, Recall {: .2f}, F1 {: .2f}'.format(i, precision, recall, F1))\n",
    "    logger.info('macro_f1: {}\\n'.format(macro_F1))\n",
    "\n",
    "    return macro_F1\n",
    "\n",
    "# 模型训练函数\n",
    "def xgbTrain(feature_df: pd.DataFrame) -> xgb.XGBModel:\n",
    "    '''\n",
    "    feature_df: 要求最后3列为: label, sn, fault_time, 其余列均为特征\n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    feature_name_list = list(feature_df.columns)[0:-3]\n",
    "    feature = np.array(feature_df[feature_name_list])\n",
    "    label = np.array(feature_df['label'])\n",
    "    label_df = feature_df[['sn', 'fault_time', 'label']]\n",
    "    prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "    train_data = xgb.DMatrix(feature, label=label)\n",
    "    train_feature = xgb.DMatrix(feature)\n",
    "    logger.info('开始训练xgb模型')\n",
    "    xgb_model = xgb.train(xgb_params, train_data, num_boost_round=500)\n",
    "    logger.info('训练xgb模型结束')\n",
    "    # 训练集指标评估\n",
    "    prediction = xgb_model.predict(train_feature)\n",
    "    prediction_df['label'] = prediction\n",
    "    logger.info('训练集评估效果: ')\n",
    "    macro_f1(label_df, prediction_df)\n",
    "\n",
    "    return xgb_model\n",
    "\n",
    "# xgb模型预测函数\n",
    "def xgbPredict(model: xgb.XGBModel, feature_df: pd.DataFrame, label_df = None) -> pd.DataFrame:\n",
    "    '''\n",
    "        feature_df: 要求最后3列为: label, sn, fault_time, 其余列均为特征\n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    if label_df is None:\n",
    "        feature_name_list = list(feature_df.columns)[0:-3]\n",
    "        feature = np.array(feature_df[feature_name_list])\n",
    "        prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "        test_feature = xgb.DMatrix(feature)\n",
    "        logger.info('开始xgb模型预测')\n",
    "        prediction = model.predict(test_feature)\n",
    "        logger.info('xgb模型预测结束')\n",
    "        prediction_df['label'] = prediction\n",
    "        prediction_df['label'] = prediction_df['label'].apply(lambda x: int(x))\n",
    "\n",
    "    else:\n",
    "        feature_name_list = list(feature_df.columns)[0:-3]\n",
    "        feature = np.array(feature_df[feature_name_list])\n",
    "        prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "        test_feature = xgb.DMatrix(feature)\n",
    "        logger.info('开始xgb模型预测')\n",
    "        prediction = model.predict(test_feature)\n",
    "        logger.info('xgb模型预测结束')\n",
    "        # 测试集指标评估\n",
    "        prediction_df['label'] = prediction\n",
    "        prediction_df['label'] = prediction_df['label'].apply(lambda x: int(x))\n",
    "        logger.info('测试集评估效果: ')\n",
    "        macro_f1(label_df, prediction_df)\n",
    "\n",
    "    return prediction_df\n",
    "\n",
    "\n",
    "# xgb模型随机训练并投票预测\n",
    "def xgbRandomTrainPredict(train_feature_df: pd.DataFrame, test_feature_df: pd.DataFrame, label_df = None) -> pd.DataFrame:\n",
    "    ## 每个子模型样本均衡，利用投票规则生成最终预测\n",
    "    random.seed(0)\n",
    "    N = 50 # number of the models\n",
    "    num_sample = 700 # number of samples for each label\n",
    "\n",
    "    _label0_index_list = list(train_feature_df[train_feature_df['label'] == 0].index)\n",
    "    _label1_index_list = list(train_feature_df[train_feature_df['label'] == 1].index)\n",
    "    _label2_index_list = list(train_feature_df[train_feature_df['label'] == 2].index)\n",
    "    _label3_index_list = list(train_feature_df[train_feature_df['label'] == 3].index)\n",
    "    feature_name_list = list(train_feature_df.columns)[0:-3]\n",
    "    test_feature = np.array(test_feature_df[feature_name_list])\n",
    "    test_feature = xgb.DMatrix(test_feature)\n",
    "    prediction_df = test_feature_df[['sn', 'fault_time']]\n",
    "\n",
    "    for iter in np.arange(N):\n",
    "        idx_0 = random.sample(_label0_index_list, num_sample)\n",
    "        idx_1 = random.sample(_label1_index_list, num_sample)\n",
    "        idx_2 = random.sample(_label2_index_list, num_sample)\n",
    "        idx_3 = random.sample(_label3_index_list, num_sample)\n",
    "        idx = np.hstack((idx_0, idx_1, idx_2, idx_3))\n",
    "        random.shuffle(idx)\n",
    "        sub_train_feature_df = train_feature_df.loc[idx, :]\n",
    "        sub_train_feature = np.array(sub_train_feature_df[feature_name_list])\n",
    "        sub_train_label = np.array(sub_train_feature_df['label'])\n",
    "        sub_train_data = xgb.DMatrix(sub_train_feature,label = sub_train_label)\n",
    "\n",
    "        logger.info('开始第{}轮训练和预测'.format(iter))\n",
    "        sub_xgb_model = xgb.train(xgb_params, sub_train_data, num_boost_round=500)\n",
    "        sub_test_pred = sub_xgb_model.predict(test_feature)\n",
    "        if iter == 0:\n",
    "            val_pred = sub_test_pred\n",
    "        else:\n",
    "            val_pred = np.vstack((val_pred, sub_test_pred))\n",
    "        logger.info('第{}轮训练和预测结束'.format(iter))\n",
    "\n",
    "    # 训练集指标评估\n",
    "    final_pred = [np.argmax(np.bincount(val_pred[:, i].astype(int))) for i in np.arange(val_pred.shape[1])]\n",
    "    final_pred = np.array(final_pred).astype(int)\n",
    "    prediction_df['label'] = final_pred\n",
    "    logger.info('训练集评估效果: ')\n",
    "    macro_f1(label_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56371e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 01:46:07,458 15968 1233114567.py[line:236] - INFO: 开始拼接日志和标签数据\n",
      "2022-05-13 01:46:08,246 15968 1233114567.py[line:245] - INFO: 拼接日志和标签数据结束\n",
      "2022-05-13 01:46:08,247 15968 1233114567.py[line:247] - INFO: 开始匹配日志和标签\n",
      "2022-05-13 01:46:08,248 15968 1233114567.py[line:248] - INFO: 使用报错时间截断进行划分\n",
      "2022-05-13 01:46:09,022 15968 1233114567.py[line:253] - INFO: 匹配日志和标签结束\n",
      "2022-05-13 01:46:09,023 15968 1233114567.py[line:255] - INFO: 开始计算统计特征\n",
      "2022-05-13 01:46:53,831 15968 1233114567.py[line:258] - INFO: 计算统计特征结束\n",
      "2022-05-13 01:46:53,836 15968 1233114567.py[line:264] - INFO: 开始计算词频特征\n",
      "0 2022-05-13 01:46:53.836534\n",
      "100 2022-05-13 01:46:57.090045\n",
      "200 2022-05-13 01:47:00.224044\n",
      "2022-05-13 01:47:02,702 15968 1233114567.py[line:274] - INFO: 计算词频特征结束\n",
      "2022-05-13 01:47:04,305 15968 1233114567.py[line:285] - INFO: 最后3列为: label, sn, fault_time, 其余列均为特征\n",
      "2022-05-13 01:47:04,305 15968 1233114567.py[line:286] - INFO: 数据条数: 16604, 特征个数: 303\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(sys.path[0]))\n",
    "# 忽略warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "# 读取sel日志数据\n",
    "sel_log_df = pd.read_csv('./data/preliminary_sel_log_dataset.csv').drop_duplicates()\n",
    "# 读取训练标签数据：有重复数据！\n",
    "train_label1 = pd.read_csv('./data/preliminary_train_label_dataset.csv')\n",
    "train_label2 = pd.read_csv('./data/preliminary_train_label_dataset_s.csv')\n",
    "train_label_df = pd.concat([train_label1,train_label2],axis=0).drop_duplicates()\n",
    "# 读取初赛A榜测试集\n",
    "preliminary_sel_log_dataset_a = pd.read_csv('./data/preliminary_sel_log_dataset_a.csv')\n",
    "preliminary_submit_dataset_a = pd.read_csv('./data/preliminary_submit_dataset_a.csv')\n",
    "preliminary_submit_dataset_a['label'] = -1\n",
    "# 读取初赛B榜测试集\n",
    "preliminary_sel_log_dataset_b = pd.read_csv('./data/preliminary_sel_log_dataset_b.csv')\n",
    "preliminary_submit_dataset_b = pd.read_csv('./data/preliminary_submit_dataset_b.csv')\n",
    "preliminary_submit_dataset_b['label'] = -1\n",
    "# preliminary_submit_dataset_b_v1p8 = pd.read_csv('./user_data/tmp_data/preliminary_submit_dataset_b_v1p8.csv')\n",
    "# 读取词列表\n",
    "v1_word_list = list(pd.read_csv('./user_data/words/word_frequency_df.txt',sep='\\t')['word'])\n",
    "v1p1_word_list = list(pd.read_csv('./user_data/words/tags_incomplete.txt',sep='\\t',names=['word'])['word'])\n",
    "word_list = list(set(v1_word_list+v1p1_word_list))\n",
    "important_word_list = list(pd.read_csv('./user_data/words/important_word_df.csv')['word'])\n",
    "\n",
    "# 获取特征\n",
    "# 计算特征\n",
    "train_feature_df = caculateFeature(sel_log_df, train_label_df, important_word_list)\n",
    "# train_feature_df.to_csv('./user_data/feature_data/train_feature_df.csv', index=None)\n",
    "random.seed(0)\n",
    "val_mask = [random.random() < 0.3 for _ in range(len(train_feature_df))]\n",
    "train_mask = [not xx for xx in val_mask]\n",
    "temp_feature_df = train_feature_df[train_mask]\n",
    "val_feature_df = train_feature_df[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c253f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 01:59:29,167 15968 2625477693.py[line:434] - INFO: 开始第0轮训练和预测\n",
      "[01:59:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:59:33,592 15968 2625477693.py[line:441] - INFO: 第0轮训练和预测结束\n",
      "2022-05-13 01:59:33,619 15968 2625477693.py[line:434] - INFO: 开始第1轮训练和预测\n",
      "[01:59:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:59:38,211 15968 2625477693.py[line:441] - INFO: 第1轮训练和预测结束\n",
      "2022-05-13 01:59:38,238 15968 2625477693.py[line:434] - INFO: 开始第2轮训练和预测\n",
      "[01:59:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:38] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:59:42,642 15968 2625477693.py[line:441] - INFO: 第2轮训练和预测结束\n",
      "2022-05-13 01:59:42,668 15968 2625477693.py[line:434] - INFO: 开始第3轮训练和预测\n",
      "[01:59:42] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:59:47,271 15968 2625477693.py[line:441] - INFO: 第3轮训练和预测结束\n",
      "2022-05-13 01:59:47,300 15968 2625477693.py[line:434] - INFO: 开始第4轮训练和预测\n",
      "[01:59:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:59:52,057 15968 2625477693.py[line:441] - INFO: 第4轮训练和预测结束\n",
      "2022-05-13 01:59:52,083 15968 2625477693.py[line:434] - INFO: 开始第5轮训练和预测\n",
      "[01:59:52] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:59:56,987 15968 2625477693.py[line:441] - INFO: 第5轮训练和预测结束\n",
      "2022-05-13 01:59:57,014 15968 2625477693.py[line:434] - INFO: 开始第6轮训练和预测\n",
      "[01:59:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:01,883 15968 2625477693.py[line:441] - INFO: 第6轮训练和预测结束\n",
      "2022-05-13 02:00:01,910 15968 2625477693.py[line:434] - INFO: 开始第7轮训练和预测\n",
      "[02:00:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:06,826 15968 2625477693.py[line:441] - INFO: 第7轮训练和预测结束\n",
      "2022-05-13 02:00:06,853 15968 2625477693.py[line:434] - INFO: 开始第8轮训练和预测\n",
      "[02:00:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:11,813 15968 2625477693.py[line:441] - INFO: 第8轮训练和预测结束\n",
      "2022-05-13 02:00:11,839 15968 2625477693.py[line:434] - INFO: 开始第9轮训练和预测\n",
      "[02:00:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:16,804 15968 2625477693.py[line:441] - INFO: 第9轮训练和预测结束\n",
      "2022-05-13 02:00:16,830 15968 2625477693.py[line:434] - INFO: 开始第10轮训练和预测\n",
      "[02:00:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 02:00:21,815 15968 2625477693.py[line:441] - INFO: 第10轮训练和预测结束\n",
      "2022-05-13 02:00:21,842 15968 2625477693.py[line:434] - INFO: 开始第11轮训练和预测\n",
      "[02:00:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:26,880 15968 2625477693.py[line:441] - INFO: 第11轮训练和预测结束\n",
      "2022-05-13 02:00:26,906 15968 2625477693.py[line:434] - INFO: 开始第12轮训练和预测\n",
      "[02:00:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:31,931 15968 2625477693.py[line:441] - INFO: 第12轮训练和预测结束\n",
      "2022-05-13 02:00:31,957 15968 2625477693.py[line:434] - INFO: 开始第13轮训练和预测\n",
      "[02:00:31] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:37,039 15968 2625477693.py[line:441] - INFO: 第13轮训练和预测结束\n",
      "2022-05-13 02:00:37,065 15968 2625477693.py[line:434] - INFO: 开始第14轮训练和预测\n",
      "[02:00:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:41,914 15968 2625477693.py[line:441] - INFO: 第14轮训练和预测结束\n",
      "2022-05-13 02:00:41,941 15968 2625477693.py[line:434] - INFO: 开始第15轮训练和预测\n",
      "[02:00:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:46,791 15968 2625477693.py[line:441] - INFO: 第15轮训练和预测结束\n",
      "2022-05-13 02:00:46,818 15968 2625477693.py[line:434] - INFO: 开始第16轮训练和预测\n",
      "[02:00:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:00:51,662 15968 2625477693.py[line:441] - INFO: 第16轮训练和预测结束\n",
      "2022-05-13 02:00:51,689 15968 2625477693.py[line:434] - INFO: 开始第17轮训练和预测\n",
      "[02:00:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:00:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:01,577 15968 2625477693.py[line:441] - INFO: 第17轮训练和预测结束\n",
      "2022-05-13 02:01:01,608 15968 2625477693.py[line:434] - INFO: 开始第18轮训练和预测\n",
      "[02:01:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:17,427 15968 2625477693.py[line:441] - INFO: 第18轮训练和预测结束\n",
      "2022-05-13 02:01:17,459 15968 2625477693.py[line:434] - INFO: 开始第19轮训练和预测\n",
      "[02:01:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:25,531 15968 2625477693.py[line:441] - INFO: 第19轮训练和预测结束\n",
      "2022-05-13 02:01:25,556 15968 2625477693.py[line:434] - INFO: 开始第20轮训练和预测\n",
      "[02:01:25] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:30,016 15968 2625477693.py[line:441] - INFO: 第20轮训练和预测结束\n",
      "2022-05-13 02:01:30,042 15968 2625477693.py[line:434] - INFO: 开始第21轮训练和预测\n",
      "[02:01:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 02:01:34,643 15968 2625477693.py[line:441] - INFO: 第21轮训练和预测结束\n",
      "2022-05-13 02:01:34,670 15968 2625477693.py[line:434] - INFO: 开始第22轮训练和预测\n",
      "[02:01:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:39,274 15968 2625477693.py[line:441] - INFO: 第22轮训练和预测结束\n",
      "2022-05-13 02:01:39,301 15968 2625477693.py[line:434] - INFO: 开始第23轮训练和预测\n",
      "[02:01:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:44,138 15968 2625477693.py[line:441] - INFO: 第23轮训练和预测结束\n",
      "2022-05-13 02:01:44,165 15968 2625477693.py[line:434] - INFO: 开始第24轮训练和预测\n",
      "[02:01:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:49,135 15968 2625477693.py[line:441] - INFO: 第24轮训练和预测结束\n",
      "2022-05-13 02:01:49,161 15968 2625477693.py[line:434] - INFO: 开始第25轮训练和预测\n",
      "[02:01:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:54,032 15968 2625477693.py[line:441] - INFO: 第25轮训练和预测结束\n",
      "2022-05-13 02:01:54,061 15968 2625477693.py[line:434] - INFO: 开始第26轮训练和预测\n",
      "[02:01:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:01:58,898 15968 2625477693.py[line:441] - INFO: 第26轮训练和预测结束\n",
      "2022-05-13 02:01:58,926 15968 2625477693.py[line:434] - INFO: 开始第27轮训练和预测\n",
      "[02:01:58] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:01:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:03,855 15968 2625477693.py[line:441] - INFO: 第27轮训练和预测结束\n",
      "2022-05-13 02:02:03,882 15968 2625477693.py[line:434] - INFO: 开始第28轮训练和预测\n",
      "[02:02:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:08,824 15968 2625477693.py[line:441] - INFO: 第28轮训练和预测结束\n",
      "2022-05-13 02:02:08,851 15968 2625477693.py[line:434] - INFO: 开始第29轮训练和预测\n",
      "[02:02:08] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:14,331 15968 2625477693.py[line:441] - INFO: 第29轮训练和预测结束\n",
      "2022-05-13 02:02:14,361 15968 2625477693.py[line:434] - INFO: 开始第30轮训练和预测\n",
      "[02:02:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:19,179 15968 2625477693.py[line:441] - INFO: 第30轮训练和预测结束\n",
      "2022-05-13 02:02:19,205 15968 2625477693.py[line:434] - INFO: 开始第31轮训练和预测\n",
      "[02:02:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:24,437 15968 2625477693.py[line:441] - INFO: 第31轮训练和预测结束\n",
      "2022-05-13 02:02:24,467 15968 2625477693.py[line:434] - INFO: 开始第32轮训练和预测\n",
      "[02:02:24] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 02:02:29,308 15968 2625477693.py[line:441] - INFO: 第32轮训练和预测结束\n",
      "2022-05-13 02:02:29,335 15968 2625477693.py[line:434] - INFO: 开始第33轮训练和预测\n",
      "[02:02:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:34,661 15968 2625477693.py[line:441] - INFO: 第33轮训练和预测结束\n",
      "2022-05-13 02:02:34,687 15968 2625477693.py[line:434] - INFO: 开始第34轮训练和预测\n",
      "[02:02:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:39,676 15968 2625477693.py[line:441] - INFO: 第34轮训练和预测结束\n",
      "2022-05-13 02:02:39,704 15968 2625477693.py[line:434] - INFO: 开始第35轮训练和预测\n",
      "[02:02:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:44,626 15968 2625477693.py[line:441] - INFO: 第35轮训练和预测结束\n",
      "2022-05-13 02:02:44,652 15968 2625477693.py[line:434] - INFO: 开始第36轮训练和预测\n",
      "[02:02:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:49,503 15968 2625477693.py[line:441] - INFO: 第36轮训练和预测结束\n",
      "2022-05-13 02:02:49,530 15968 2625477693.py[line:434] - INFO: 开始第37轮训练和预测\n",
      "[02:02:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:54,435 15968 2625477693.py[line:441] - INFO: 第37轮训练和预测结束\n",
      "2022-05-13 02:02:54,461 15968 2625477693.py[line:434] - INFO: 开始第38轮训练和预测\n",
      "[02:02:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:02:59,555 15968 2625477693.py[line:441] - INFO: 第38轮训练和预测结束\n",
      "2022-05-13 02:02:59,583 15968 2625477693.py[line:434] - INFO: 开始第39轮训练和预测\n",
      "[02:02:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:02:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:04,458 15968 2625477693.py[line:441] - INFO: 第39轮训练和预测结束\n",
      "2022-05-13 02:03:04,484 15968 2625477693.py[line:434] - INFO: 开始第40轮训练和预测\n",
      "[02:03:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:17,115 15968 2625477693.py[line:441] - INFO: 第40轮训练和预测结束\n",
      "2022-05-13 02:03:17,145 15968 2625477693.py[line:434] - INFO: 开始第41轮训练和预测\n",
      "[02:03:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:27,621 15968 2625477693.py[line:441] - INFO: 第41轮训练和预测结束\n",
      "2022-05-13 02:03:27,647 15968 2625477693.py[line:434] - INFO: 开始第42轮训练和预测\n",
      "[02:03:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:32,154 15968 2625477693.py[line:441] - INFO: 第42轮训练和预测结束\n",
      "2022-05-13 02:03:32,180 15968 2625477693.py[line:434] - INFO: 开始第43轮训练和预测\n",
      "[02:03:32] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 02:03:36,646 15968 2625477693.py[line:441] - INFO: 第43轮训练和预测结束\n",
      "2022-05-13 02:03:36,672 15968 2625477693.py[line:434] - INFO: 开始第44轮训练和预测\n",
      "[02:03:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:41,648 15968 2625477693.py[line:441] - INFO: 第44轮训练和预测结束\n",
      "2022-05-13 02:03:41,676 15968 2625477693.py[line:434] - INFO: 开始第45轮训练和预测\n",
      "[02:03:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:46,351 15968 2625477693.py[line:441] - INFO: 第45轮训练和预测结束\n",
      "2022-05-13 02:03:46,377 15968 2625477693.py[line:434] - INFO: 开始第46轮训练和预测\n",
      "[02:03:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:51,246 15968 2625477693.py[line:441] - INFO: 第46轮训练和预测结束\n",
      "2022-05-13 02:03:51,273 15968 2625477693.py[line:434] - INFO: 开始第47轮训练和预测\n",
      "[02:03:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:03:55,784 15968 2625477693.py[line:441] - INFO: 第47轮训练和预测结束\n",
      "2022-05-13 02:03:55,811 15968 2625477693.py[line:434] - INFO: 开始第48轮训练和预测\n",
      "[02:03:55] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:03:55] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:04:00,560 15968 2625477693.py[line:441] - INFO: 第48轮训练和预测结束\n",
      "2022-05-13 02:04:00,592 15968 2625477693.py[line:434] - INFO: 开始第49轮训练和预测\n",
      "[02:04:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:04:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 02:04:05,447 15968 2625477693.py[line:441] - INFO: 第49轮训练和预测结束\n",
      "2022-05-13 02:04:05,486 15968 2625477693.py[line:447] - INFO: 训练集评估效果: \n",
      "2022-05-13 02:04:05,494 15968 2625477693.py[line:334] - INFO: Label 0:   Precision  0.42, Recall  0.57, F1  0.48\n",
      "2022-05-13 02:04:05,496 15968 2625477693.py[line:334] - INFO: Label 1:   Precision  0.70, Recall  0.63, F1  0.66\n",
      "2022-05-13 02:04:05,498 15968 2625477693.py[line:334] - INFO: Label 2:   Precision  0.97, Recall  0.92, F1  0.94\n",
      "2022-05-13 02:04:05,501 15968 2625477693.py[line:334] - INFO: Label 3:   Precision  0.86, Recall  0.93, F1  0.89\n",
      "2022-05-13 02:04:05,501 15968 2625477693.py[line:335] - INFO: macro_f1: 0.6261052299531462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgb训练预测\n",
    "# 100 500 0.6303\n",
    "# 50 700 0.6261\n",
    "predictions = xgbRandomTrainPredict(temp_feature_df, val_feature_df, val_feature_df[['sn', 'fault_time', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f219e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 01:45:40,780 15968 3915516630.py[line:34] - INFO: 开始第0轮训练和预测\n",
      "[01:45:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:45:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:45:46,567 15968 3915516630.py[line:41] - INFO: 第0轮训练和预测结束\n",
      "2022-05-13 01:45:46,590 15968 3915516630.py[line:34] - INFO: 开始第1轮训练和预测\n",
      "[01:45:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:45:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m sub_train_data \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(sub_train_feature,label \u001b[38;5;241m=\u001b[39m sub_train_label)\n\u001b[0;32m     34\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m开始第\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m轮训练和预测\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28miter\u001b[39m))\n\u001b[1;32m---> 35\u001b[0m sub_xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m sub_test_pred \u001b[38;5;241m=\u001b[39m sub_xgb_model\u001b[38;5;241m.\u001b[39mpredict(test_feature)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_feature_df = temp_feature_df\n",
    "test_feature_df = val_feature_df\n",
    "label_df = val_feature_df[['sn', 'fault_time', 'label']]\n",
    "\n",
    "\n",
    "## 每个子模型样本均衡，利用投票规则生成最终预测\n",
    "random.seed(0)\n",
    "N = 100 # number of the models\n",
    "num_sample = 500 # number of samples for each label\n",
    "train_feature_df\n",
    "\n",
    "\n",
    "_label0_index_list = list(train_feature_df[train_feature_df['label'] == 0].index)\n",
    "_label1_index_list = list(train_feature_df[train_feature_df['label'] == 1].index)\n",
    "_label2_index_list = list(train_feature_df[train_feature_df['label'] == 2].index)\n",
    "_label3_index_list = list(train_feature_df[train_feature_df['label'] == 3].index)\n",
    "feature_name_list = list(train_feature_df.columns)[0:-3]\n",
    "test_feature = np.array(test_feature_df[feature_name_list])\n",
    "test_feature = xgb.DMatrix(test_feature)\n",
    "prediction_df = test_feature_df[['sn', 'fault_time']]\n",
    "\n",
    "for iter in np.arange(N):\n",
    "    idx_0 = random.sample(_label0_index_list, num_sample)\n",
    "    idx_1 = random.sample(_label1_index_list, num_sample)\n",
    "    idx_2 = random.sample(_label2_index_list, num_sample)\n",
    "    idx_3 = random.sample(_label3_index_list, num_sample)\n",
    "    idx = np.hstack((idx_0, idx_1, idx_2, idx_3))\n",
    "    random.shuffle(idx)\n",
    "    sub_train_feature_df = train_feature_df.loc[idx, :]\n",
    "    sub_train_feature = np.array(sub_train_feature_df[feature_name_list])\n",
    "    sub_train_label = np.array(sub_train_feature_df['label'])\n",
    "    sub_train_data = xgb.DMatrix(sub_train_feature,label = sub_train_label)\n",
    "\n",
    "    logger.info('开始第{}轮训练和预测'.format(iter))\n",
    "    sub_xgb_model = xgb.train(xgb_params, sub_train_data, num_boost_round=500)\n",
    "    sub_test_pred = sub_xgb_model.predict(test_feature)\n",
    "    if iter == 0:\n",
    "        val_pred = sub_test_pred\n",
    "    else:\n",
    "        val_pred = np.vstack((val_pred, sub_test_pred))\n",
    "    logger.info('第{}轮训练和预测结束'.format(iter))\n",
    "\n",
    "# 训练集指标评估\n",
    "final_pred = [np.argmax(np.bincount(val_pred[:, i].astype(int))) for i in np.arange(val_pred.shape[1])]\n",
    "final_pred = np.array(final_pred).astype(int)\n",
    "prediction_df['label'] = final_pred\n",
    "logger.info('训练集评估效果: ')\n",
    "macro_f1(label_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0105e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     4,     5,     6,     7,     8,     9,\n",
       "               10,\n",
       "            ...\n",
       "            16593, 16594, 16595, 16596, 16597, 16598, 16599, 16600, 16601,\n",
       "            16603],\n",
       "           dtype='int64', length=11617)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_df.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Log_diagosis_python",
   "language": "python",
   "name": "log_diagosis_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
