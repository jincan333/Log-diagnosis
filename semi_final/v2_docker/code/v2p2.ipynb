{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ac94bf",
   "metadata": {},
   "source": [
    "# 词汇仅使用重要性进入V2前300的 + 100轮随机训练和预测投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d587f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinca\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from logging import handlers\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import traceback\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "## 日志格式设置\n",
    "# 日志级别关系映射\n",
    "level_relations = {\n",
    "    'debug': logging.DEBUG,\n",
    "    'info': logging.INFO,\n",
    "    'warning': logging.WARNING,\n",
    "    'error': logging.ERROR,\n",
    "    'crit': logging.CRITICAL\n",
    "}\n",
    "def get_logger(filename, level='info'):\n",
    "    # 创建日志对象\n",
    "    log = logging.getLogger(filename)\n",
    "    # 设置日志级别\n",
    "    log.setLevel(level_relations.get(level))\n",
    "    # 日志输出格式\n",
    "    fmt = logging.Formatter('%(asctime)s %(thread)d %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "    # 输出到控制台\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(fmt)\n",
    "    # 输出到文件\n",
    "    # 日志文件按天进行保存，每天一个日志文件\n",
    "    file_handler = handlers.TimedRotatingFileHandler(filename=filename, when='D', backupCount=1, encoding='utf-8')\n",
    "    # 按照大小自动分割日志文件，一旦达到指定的大小重新生成文件\n",
    "    # file_handler = handlers.RotatingFileHandler(filename=filename, maxBytes=1*1024*1024*1024, backupCount=1, encoding='utf-8')\n",
    "    file_handler.setFormatter(fmt)\n",
    "    if not log.handlers:\n",
    "        log.addHandler(console_handler)\n",
    "        log.addHandler(file_handler)\n",
    "    return log\n",
    "\n",
    "# sn分组后，本次报错和上次报错之间的日志匹配到本次报错\n",
    "def divideLogByFaultTime(log_label_df: pd.DataFrame):\n",
    "    log_correspond_label_df = pd.DataFrame(columns=['sn', 'fault_time', 'msg', 'time', 'server_model', 'label'])\n",
    "    no_label_log_list = []\n",
    "    log_label_df = log_label_df.reset_index(drop=True)\n",
    "\n",
    "    for sn, log in log_label_df.groupby('sn'):\n",
    "        if len(log[log['label'] != '']) == 0:\n",
    "            no_label_log_list.append(log)\n",
    "        elif len(log[log['label'] != '']) == 1:\n",
    "            msg_df = log[log['label'] == '']\n",
    "            msg_df['label'] = log[log['label'] != '']['label'].iloc[0]\n",
    "            msg_df['fault_time'] = log[log['label'] != '']['time'].iloc[0]\n",
    "            log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "        else:\n",
    "            # 使用index的顺序取数时，要注意index必须按所需的顺序排列\n",
    "            cutoff_index = [-1] + log.loc[log['label'] != ''].index.tolist() + [log.index.tolist()[-1] + 1]\n",
    "            for kth in range(len(cutoff_index) - 1):\n",
    "                temp_log = log.loc[(log.index <= cutoff_index[kth + 1]) & (log.index > cutoff_index[kth])]\n",
    "                if len(temp_log) > 0:\n",
    "                    if len(temp_log[temp_log['label'] != '']) == 0:\n",
    "                        no_label_log_list.append(temp_log)\n",
    "                    # 只有标签，没有日志的数据，把标签的部分数据直接作为日志\n",
    "                    elif len(temp_log) == 1:\n",
    "                        msg_df = temp_log\n",
    "                        msg_df['fault_time'] = temp_log[temp_log['label'] != '']['time'].iloc[0]\n",
    "                        log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "                    else:\n",
    "                        msg_df = temp_log[temp_log['label'] == '']\n",
    "                        msg_df['label'] = temp_log[temp_log['label'] != '']['label'].iloc[0]\n",
    "                        msg_df['fault_time'] = temp_log[temp_log['label'] != '']['time'].iloc[0]\n",
    "                        log_correspond_label_df = pd.concat([log_correspond_label_df, msg_df])\n",
    "    return log_correspond_label_df, no_label_log_list\n",
    "\n",
    "# 计算统计特征\n",
    "def calculateStatisticFeature(log_correspond_label_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    use_log_label_df = log_correspond_label_df\n",
    "\n",
    "    use_log_label_df['msg_hour'] = use_log_label_df['time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    use_log_label_df['msg_minute'] = use_log_label_df['time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").minute)\n",
    "    use_log_label_df['fault_hour'] = use_log_label_df['fault_time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    use_log_label_df['fault_minute'] = use_log_label_df['fault_time'].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").minute)\n",
    "\n",
    "    # 0408新增\n",
    "    # 最近一次日志时间距报错时间间隔，单位秒\n",
    "    nearest_msg_fault_time_delta_list = []\n",
    "    # 日志不去重时长度1,2,3,4日志数量统计\n",
    "    all_msg_1_cnt_list = []\n",
    "    all_msg_2_cnt_list = []\n",
    "    all_msg_3_cnt_list = []\n",
    "    all_msg_4_cnt_list = []\n",
    "\n",
    "    fault_minute_list = []\n",
    "    msg_1_cnt_list = []\n",
    "    msg_2_cnt_list = []\n",
    "    msg_3_cnt_list = []\n",
    "    msg_4_cnt_list = []\n",
    "    msg_hour_max_list = []\n",
    "    msg_hour_min_list = []\n",
    "    msg_hour_avg_list = []\n",
    "    msg_hour_median_list = []\n",
    "    msg_hour_mode_list = []\n",
    "    msg_minute_max_list = []\n",
    "    msg_minute_min_list = []\n",
    "    msg_minute_avg_list = []\n",
    "    msg_minute_median_list = []\n",
    "    msg_minute_mode_list = []\n",
    "\n",
    "    sn_list = []\n",
    "    server_model_list = []\n",
    "    msg_log_list = []\n",
    "    msg_cnt_list = []\n",
    "    fault_hour_list = []\n",
    "    label_list = []\n",
    "    fault_time_list = []\n",
    "    for msg_log_df in use_log_label_df.groupby(['sn', 'fault_time', 'label']):\n",
    "        msg_log_str = ''\n",
    "        all_msg_1_cnt = 0\n",
    "        all_msg_2_cnt = 0\n",
    "        all_msg_3_cnt = 0\n",
    "        all_msg_4_cnt = 0\n",
    "        msg_1_cnt = 0\n",
    "        msg_2_cnt = 0\n",
    "        msg_3_cnt = 0\n",
    "        msg_4_cnt = 0\n",
    "        for info in msg_log_df[1]['msg']:\n",
    "            if info == info:\n",
    "                if len(info.split('|')) == 1:\n",
    "                    all_msg_1_cnt += 1\n",
    "                elif len(info.split('|')) == 2:\n",
    "                    all_msg_2_cnt += 1\n",
    "                elif len(info.split('|')) == 3:\n",
    "                    all_msg_3_cnt += 1\n",
    "                else:\n",
    "                    all_msg_4_cnt += 1\n",
    "        for info in msg_log_df[1]['msg'].drop_duplicates():\n",
    "            if info == info:\n",
    "                msg_log_str = msg_log_str + info.lower() + '.'\n",
    "                if len(info.split('|')) == 1:\n",
    "                    msg_1_cnt += 1\n",
    "                elif len(info.split('|')) == 2:\n",
    "                    msg_2_cnt += 1\n",
    "                elif len(info.split('|')) == 3:\n",
    "                    msg_3_cnt += 1\n",
    "                else:\n",
    "                    msg_4_cnt += 1\n",
    "        nearest_msg_fault_time_delta = abs(datetime.strptime(msg_log_df[1].iloc[-1]['time'], '%Y-%m-%d %H:%M:%S'\n",
    "                                                             ) - datetime.strptime(msg_log_df[0][1],\n",
    "                                                                                   '%Y-%m-%d %H:%M:%S'))\n",
    "        nearest_msg_fault_time_delta = nearest_msg_fault_time_delta.days * 24 * 3600 + nearest_msg_fault_time_delta.seconds\n",
    "        sm = int(msg_log_df[1].iloc[0]['server_model'][2:])\n",
    "\n",
    "        sn_list.append(msg_log_df[0][0])\n",
    "        fault_time_list.append(msg_log_df[0][1])\n",
    "        label_list.append(msg_log_df[0][2])\n",
    "\n",
    "        nearest_msg_fault_time_delta_list.append(nearest_msg_fault_time_delta)\n",
    "        server_model_list.append(sm)\n",
    "        msg_log_list.append(msg_log_str)\n",
    "        msg_cnt_list.append(len(msg_log_df[1]))\n",
    "\n",
    "        fault_hour_list.append(msg_log_df[1].iloc[0]['fault_hour'])\n",
    "        fault_minute_list.append(msg_log_df[1].iloc[0]['fault_minute'])\n",
    "\n",
    "        all_msg_1_cnt_list.append(all_msg_1_cnt)\n",
    "        all_msg_2_cnt_list.append(all_msg_2_cnt)\n",
    "        all_msg_3_cnt_list.append(all_msg_3_cnt)\n",
    "        all_msg_4_cnt_list.append(all_msg_4_cnt)\n",
    "\n",
    "        msg_1_cnt_list.append(msg_1_cnt)\n",
    "        msg_2_cnt_list.append(msg_2_cnt)\n",
    "        msg_3_cnt_list.append(msg_3_cnt)\n",
    "        msg_4_cnt_list.append(msg_4_cnt)\n",
    "\n",
    "        msg_hour_max_list.append(msg_log_df[1]['msg_hour'].max())\n",
    "        msg_hour_min_list.append(msg_log_df[1]['msg_hour'].min())\n",
    "        msg_hour_avg_list.append(msg_log_df[1]['msg_hour'].mean())\n",
    "        msg_hour_median_list.append(msg_log_df[1]['msg_hour'].median())\n",
    "        msg_hour_mode_list.append(msg_log_df[1]['msg_hour'].mode()[0])\n",
    "\n",
    "        msg_minute_max_list.append(msg_log_df[1]['msg_minute'].max())\n",
    "        msg_minute_min_list.append(msg_log_df[1]['msg_minute'].min())\n",
    "        msg_minute_avg_list.append(msg_log_df[1]['msg_minute'].mean())\n",
    "        msg_minute_median_list.append(msg_log_df[1]['msg_minute'].median())\n",
    "        msg_minute_mode_list.append(msg_log_df[1]['msg_minute'].mode()[0])\n",
    "\n",
    "    msg_log_label_df = pd.DataFrame(\n",
    "        {\n",
    "            'sn': sn_list,\n",
    "            'fault_time': fault_time_list,\n",
    "            'server_model': server_model_list,\n",
    "            'msg_cnt': msg_cnt_list,\n",
    "            'fault_hour': fault_hour_list,\n",
    "            'fault_minute': fault_minute_list,\n",
    "            'nearest_msg_fault_time_delta': nearest_msg_fault_time_delta_list,\n",
    "            'all_msg_1_cnt': all_msg_1_cnt_list,\n",
    "            'all_msg_2_cnt': all_msg_2_cnt_list,\n",
    "            'all_msg_3_cnt': all_msg_3_cnt_list,\n",
    "            'all_msg_4_cnt': all_msg_4_cnt_list,\n",
    "            'msg_1_cnt': msg_1_cnt_list,\n",
    "            'msg_2_cnt': msg_2_cnt_list,\n",
    "            'msg_3_cnt': msg_3_cnt_list,\n",
    "            'msg_4_cnt': msg_4_cnt_list,\n",
    "            'msg_hour_max': msg_hour_max_list,\n",
    "            'msg_hour_min': msg_hour_min_list,\n",
    "            'msg_hour_avg': msg_hour_avg_list,\n",
    "            'msg_hour_median': msg_hour_median_list,\n",
    "            'msg_hour_mode': msg_hour_mode_list,\n",
    "            'msg_minute_max': msg_minute_max_list,\n",
    "            'msg_minute_min': msg_minute_min_list,\n",
    "            'msg_minute_avg': msg_minute_avg_list,\n",
    "            'msg_minute_median': msg_minute_median_list,\n",
    "            'msg_minute_mode': msg_minute_mode_list,\n",
    "            'msg_log': msg_log_list,\n",
    "            'label': label_list\n",
    "        }\n",
    "    )\n",
    "    return msg_log_label_df\n",
    "\n",
    "# 计算特征函数\n",
    "def caculateFeature(log_df: pd.DataFrame, label_df: pd.DataFrame, word_list: list) -> pd.DataFrame:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    logger.info('开始拼接日志和标签数据')\n",
    "    log_df['label'] = ''\n",
    "    label_df['time'] = label_df['fault_time']\n",
    "    label_df['msg'] = ''\n",
    "    label_df['server_model'] = label_df['sn'].map(dict(zip(log_df['sn'], log_df['server_model'])))\n",
    "    label_df = label_df[['sn', 'time', 'msg', 'server_model', 'label']]\n",
    "    log_label_df = pd.concat([log_df, label_df], axis=0).sort_values(by='time')\n",
    "    log_label_df['fault_time'] = ''\n",
    "    log_label_df = log_label_df[['sn', 'fault_time', 'msg', 'time', 'server_model', 'label']]\n",
    "    logger.info('拼接日志和标签数据结束')\n",
    "\n",
    "    logger.info('开始匹配日志和标签')\n",
    "    logger.info('使用报错时间截断进行划分')\n",
    "    # 使用报错时间截断进行划分\n",
    "    # FaultTime_log_correspond_label_df, FaultTime_no_label_log_list = divideLogByFaultTime(log_label_df)\n",
    "    # FaultTime_log_correspond_label_df.to_csv('./user_data/tmp_data/FaultTime_log_correspond_label_df.csv', index = None)\n",
    "    FaultTime_log_correspond_label_df = pd.read_csv('./user_data/tmp_data/FaultTime_log_correspond_label_df.csv')\n",
    "    logger.info('匹配日志和标签结束')\n",
    "\n",
    "    logger.info('开始计算统计特征')\n",
    "    # 使用报错时间截断进行划分\n",
    "    msg_log_label_df = calculateStatisticFeature(FaultTime_log_correspond_label_df)\n",
    "    logger.info('计算统计特征结束')\n",
    "\n",
    "    msg_log_list = list(msg_log_label_df['msg_log'])\n",
    "    label_list = list(msg_log_label_df['label'])\n",
    "\n",
    "    # 计算词频向量\n",
    "    logger.info('开始计算词频特征')\n",
    "    frequency_vector_list = []\n",
    "    tag = 0\n",
    "    for word in word_list:\n",
    "        if tag % 100 == 0:\n",
    "            print(tag, datetime.now())\n",
    "        pattern = re.compile(word)\n",
    "        frequency_vector = [len(re.findall(pattern, log)) for log in msg_log_list]\n",
    "        frequency_vector_list.append(frequency_vector)\n",
    "        tag += 1\n",
    "    logger.info('计算词频特征结束')\n",
    "\n",
    "    frequency_vector_df = pd.DataFrame(frequency_vector_list)\n",
    "    frequency_vector_df = frequency_vector_df.T\n",
    "    frequency_vector_df.columns = word_list\n",
    "    statistic_feature_list = list(msg_log_label_df.columns)[2:-2]\n",
    "    feature_df = frequency_vector_df\n",
    "    feature_df[statistic_feature_list] = msg_log_label_df[statistic_feature_list]\n",
    "\n",
    "    feature_df['label'] = label_list\n",
    "    feature_df[['sn', 'fault_time']] = msg_log_label_df[['sn', 'fault_time']]\n",
    "    logger.info('最后3列为: label, sn, fault_time, 其余列均为特征')\n",
    "    logger.info('数据条数: {}, 特征个数: {}'.format(feature_df.shape[0], feature_df.shape[1]-3))\n",
    "    return feature_df\n",
    "\n",
    "\n",
    "# xgb模型参数\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类问题\n",
    "    'num_class': 4,  # 类别数，与multi softmax并用\n",
    "    'gamma': 0.1,  # 用于控制是否后剪枝的参数，越大越保守，一般0.1 0.2的样子\n",
    "    'max_depth': 6,  # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,  # 控制模型复杂度的权重值的L2 正则化项参数，参数越大，模型越不容易过拟合\n",
    "    'subsample': 1,  # 随机采样训练样本\n",
    "    'colsample_bytree': 1,  # 这个参数默认为1，是每个叶子里面h的和至少是多少\n",
    "    # 对于正负样本不均衡时的0-1分类而言，假设h在0.01附近，min_child_weight为1\n",
    "    # 意味着叶子节点中最少需要包含100个样本。这个参数非常影响结果，\n",
    "    # 控制叶子节点中二阶导的和的最小值，该参数值越小，越容易过拟合\n",
    "    'silent': 0,  # 设置成1 则没有运行信息输入，最好是设置成0\n",
    "    'eta': 0.3,  # 如同学习率\n",
    "    'seed': 1000,\n",
    "    'nthread': 16,  # CPU线程数\n",
    "    # 'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "# 指标评估\n",
    "def macro_f1(label_df: pd.DataFrame, prediction_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param label_df: [sn,fault_time,label]\n",
    "    :param prediction_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    prediction_df.columns = ['sn', 'fault_time', 'prediction']\n",
    "    outcome_df = pd.merge(label_df, prediction_df ,how = 'left', on = ['sn', 'fault_time'])\n",
    "    weights = [5 / 11, 4 / 11, 1 / 11, 1 / 11]\n",
    "    macro_F1 = 0.\n",
    "    for i in range(len(weights)):\n",
    "        TP = len(outcome_df[(outcome_df['label'] == i) & (outcome_df['prediction'] == i)])\n",
    "        FP = len(outcome_df[(outcome_df['label'] != i) & (outcome_df['prediction'] == i)])\n",
    "        FN = len(outcome_df[(outcome_df['label'] == i) & (outcome_df['prediction'] != i)])\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        F1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        macro_F1 += weights[i] * F1\n",
    "        logger.info('Label {}:   Precision {: .2f}, Recall {: .2f}, F1 {: .2f}'.format(i, precision, recall, F1))\n",
    "    logger.info('macro_f1: {}\\n'.format(macro_F1))\n",
    "\n",
    "    return macro_F1\n",
    "\n",
    "# 模型训练函数\n",
    "def xgbTrain(feature_df: pd.DataFrame) -> xgb.XGBModel:\n",
    "    '''\n",
    "    feature_df: 要求最后3列为: label, sn, fault_time, 其余列均为特征\n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    feature_name_list = list(feature_df.columns)[0:-3]\n",
    "    feature = np.array(feature_df[feature_name_list])\n",
    "    label = np.array(feature_df['label'])\n",
    "    label_df = feature_df[['sn', 'fault_time', 'label']]\n",
    "    prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "    train_data = xgb.DMatrix(feature, label=label)\n",
    "    train_feature = xgb.DMatrix(feature)\n",
    "    logger.info('开始训练xgb模型')\n",
    "    xgb_model = xgb.train(xgb_params, train_data, num_boost_round=500)\n",
    "    logger.info('训练xgb模型结束')\n",
    "    # 训练集指标评估\n",
    "    prediction = xgb_model.predict(train_feature)\n",
    "    prediction_df['label'] = prediction\n",
    "    logger.info('训练集评估效果: ')\n",
    "    macro_f1(label_df, prediction_df)\n",
    "\n",
    "    return xgb_model\n",
    "\n",
    "# xgb模型预测函数\n",
    "def xgbPredict(model: xgb.XGBModel, feature_df: pd.DataFrame, label_df = None) -> pd.DataFrame:\n",
    "    '''\n",
    "        feature_df: 要求最后3列为: label, sn, fault_time, 其余列均为特征\n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "    logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "    if label_df is None:\n",
    "        feature_name_list = list(feature_df.columns)[0:-3]\n",
    "        feature = np.array(feature_df[feature_name_list])\n",
    "        prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "        test_feature = xgb.DMatrix(feature)\n",
    "        logger.info('开始xgb模型预测')\n",
    "        prediction = model.predict(test_feature)\n",
    "        logger.info('xgb模型预测结束')\n",
    "        prediction_df['label'] = prediction\n",
    "        prediction_df['label'] = prediction_df['label'].apply(lambda x: int(x))\n",
    "\n",
    "    else:\n",
    "        feature_name_list = list(feature_df.columns)[0:-3]\n",
    "        feature = np.array(feature_df[feature_name_list])\n",
    "        prediction_df = feature_df[['sn', 'fault_time']]\n",
    "\n",
    "        test_feature = xgb.DMatrix(feature)\n",
    "        logger.info('开始xgb模型预测')\n",
    "        prediction = model.predict(test_feature)\n",
    "        logger.info('xgb模型预测结束')\n",
    "        # 测试集指标评估\n",
    "        prediction_df['label'] = prediction\n",
    "        prediction_df['label'] = prediction_df['label'].apply(lambda x: int(x))\n",
    "        logger.info('测试集评估效果: ')\n",
    "        macro_f1(label_df, prediction_df)\n",
    "\n",
    "    return prediction_df\n",
    "\n",
    "\n",
    "# xgb模型随机训练并投票预测\n",
    "def xgbRandomTrainPredict(train_feature_df: pd.DataFrame, test_feature_df: pd.DataFrame, label_df = None) -> pd.DataFrame:\n",
    "    ## 每个子模型样本均衡，利用投票规则生成最终预测\n",
    "    random.seed(0)\n",
    "    N = 100 # number of the models\n",
    "    num_sample = 500 # number of samples for each label\n",
    "\n",
    "    _label0_index_list = list(train_feature_df[train_feature_df['label'] == 0].index)\n",
    "    _label1_index_list = list(train_feature_df[train_feature_df['label'] == 1].index)\n",
    "    _label2_index_list = list(train_feature_df[train_feature_df['label'] == 2].index)\n",
    "    _label3_index_list = list(train_feature_df[train_feature_df['label'] == 3].index)\n",
    "    feature_name_list = list(train_feature_df.columns)[0:-3]\n",
    "    test_feature = np.array(test_feature_df[feature_name_list])\n",
    "    test_feature = xgb.DMatrix(test_feature)\n",
    "    prediction_df = test_feature_df[['sn', 'fault_time']]\n",
    "\n",
    "    for iter in np.arange(N):\n",
    "        idx_0 = random.sample(_label0_index_list, num_sample)\n",
    "        idx_1 = random.sample(_label1_index_list, num_sample)\n",
    "        idx_2 = random.sample(_label2_index_list, num_sample)\n",
    "        idx_3 = random.sample(_label3_index_list, num_sample)\n",
    "        idx = np.hstack((idx_0, idx_1, idx_2, idx_3))\n",
    "        random.shuffle(idx)\n",
    "        sub_train_feature_df = train_feature_df.loc[idx, :]\n",
    "        sub_train_feature = np.array(sub_train_feature_df[feature_name_list])\n",
    "        sub_train_label = np.array(sub_train_feature_df['label'])\n",
    "        sub_train_data = xgb.DMatrix(sub_train_feature,label = sub_train_label)\n",
    "\n",
    "        logger.info('开始第{}轮训练和预测'.format(iter))\n",
    "        sub_xgb_model = xgb.train(xgb_params, sub_train_data, num_boost_round=500)\n",
    "        sub_test_pred = sub_xgb_model.predict(test_feature)\n",
    "        if iter == 0:\n",
    "            val_pred = sub_test_pred\n",
    "        else:\n",
    "            val_pred = np.vstack((val_pred, sub_test_pred))\n",
    "        logger.info('第{}轮训练和预测结束'.format(iter))\n",
    "\n",
    "    # 训练集指标评估\n",
    "    final_pred = [np.argmax(np.bincount(val_pred[:, i].astype(int))) for i in np.arange(val_pred.shape[1])]\n",
    "    final_pred = np.array(final_pred).astype(int)\n",
    "    prediction_df['label'] = final_pred\n",
    "    logger.info('训练集评估效果: ')\n",
    "    macro_f1(label_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56371e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(sys.path[0]))\n",
    "# 忽略warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = get_logger('./user_data/logs/{}_info.log'.format(date.today()), 'info')\n",
    "logger_error = get_logger('./user_data/logs/{}_error.log'.format(date.today()), 'error')\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "# 读取sel日志数据\n",
    "sel_log_df = pd.read_csv('./data/preliminary_train/preliminary_sel_log_dataset.csv').drop_duplicates()\n",
    "# 读取训练标签数据：有重复数据！\n",
    "train_label1 = pd.read_csv('./data/preliminary_train/preliminary_train_label_dataset.csv')\n",
    "train_label2 = pd.read_csv('./data/preliminary_train/preliminary_train_label_dataset_s.csv')\n",
    "train_label_df = pd.concat([train_label1,train_label2],axis=0).drop_duplicates()\n",
    "# 读取词列表\n",
    "v1_word_list = list(pd.read_csv('./user_data/words/word_frequency_df.txt',sep='\\t')['word'])\n",
    "v1p1_word_list = list(pd.read_csv('./user_data/words/tags_incomplete.txt',sep='\\t',names=['word'])['word'])\n",
    "word_list = list(set(v1_word_list+v1p1_word_list))\n",
    "important_word_list = list(pd.read_csv('./user_data/words/important_word_df.csv')['word'])\n",
    "\n",
    "# 获取特征\n",
    "# 计算特征\n",
    "# train_feature_df = caculateFeature(sel_log_df, train_label_df, important_word_list)\n",
    "# train_feature_df.to_csv('./user_data/feature_data/faulttime_train_feature_300_df.csv', index=None)\n",
    "train_feature_df = pd.read_csv('./user_data/feature_data/faulttime_train_feature_all_df.csv')\n",
    "random.seed(0)\n",
    "val_mask = [random.random() < 0.3 for _ in range(len(train_feature_df))]\n",
    "train_mask = [not xx for xx in val_mask]\n",
    "temp_feature_df = train_feature_df[train_mask]\n",
    "val_feature_df = train_feature_df[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c253f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:13:38,351 13912 1233114567.py[line:434] - INFO: 开始第0轮训练和预测\n",
      "[00:13:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:13:38] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:13:54,824 13912 1233114567.py[line:441] - INFO: 第0轮训练和预测结束\n",
      "2022-05-15 00:13:54,925 13912 1233114567.py[line:434] - INFO: 开始第1轮训练和预测\n",
      "[00:13:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:13:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:14:11,197 13912 1233114567.py[line:441] - INFO: 第1轮训练和预测结束\n",
      "2022-05-15 00:14:11,303 13912 1233114567.py[line:434] - INFO: 开始第2轮训练和预测\n",
      "[00:14:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:14:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:14:27,845 13912 1233114567.py[line:441] - INFO: 第2轮训练和预测结束\n",
      "2022-05-15 00:14:27,949 13912 1233114567.py[line:434] - INFO: 开始第3轮训练和预测\n",
      "[00:14:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:14:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:14:44,475 13912 1233114567.py[line:441] - INFO: 第3轮训练和预测结束\n",
      "2022-05-15 00:14:44,578 13912 1233114567.py[line:434] - INFO: 开始第4轮训练和预测\n",
      "[00:14:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:14:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:15:00,945 13912 1233114567.py[line:441] - INFO: 第4轮训练和预测结束\n",
      "2022-05-15 00:15:01,048 13912 1233114567.py[line:434] - INFO: 开始第5轮训练和预测\n",
      "[00:15:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:15:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:15:17,858 13912 1233114567.py[line:441] - INFO: 第5轮训练和预测结束\n",
      "2022-05-15 00:15:17,960 13912 1233114567.py[line:434] - INFO: 开始第6轮训练和预测\n",
      "[00:15:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:15:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:15:34,383 13912 1233114567.py[line:441] - INFO: 第6轮训练和预测结束\n",
      "2022-05-15 00:15:34,490 13912 1233114567.py[line:434] - INFO: 开始第7轮训练和预测\n",
      "[00:15:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:15:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:15:50,988 13912 1233114567.py[line:441] - INFO: 第7轮训练和预测结束\n",
      "2022-05-15 00:15:51,093 13912 1233114567.py[line:434] - INFO: 开始第8轮训练和预测\n",
      "[00:15:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:15:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:16:07,808 13912 1233114567.py[line:441] - INFO: 第8轮训练和预测结束\n",
      "2022-05-15 00:16:07,914 13912 1233114567.py[line:434] - INFO: 开始第9轮训练和预测\n",
      "[00:16:07] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:16:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:16:24,763 13912 1233114567.py[line:441] - INFO: 第9轮训练和预测结束\n",
      "2022-05-15 00:16:24,875 13912 1233114567.py[line:434] - INFO: 开始第10轮训练和预测\n",
      "[00:16:24] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:16:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:16:41,430 13912 1233114567.py[line:441] - INFO: 第10轮训练和预测结束\n",
      "2022-05-15 00:16:41,532 13912 1233114567.py[line:434] - INFO: 开始第11轮训练和预测\n",
      "[00:16:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:16:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:16:57,842 13912 1233114567.py[line:441] - INFO: 第11轮训练和预测结束\n",
      "2022-05-15 00:16:57,942 13912 1233114567.py[line:434] - INFO: 开始第12轮训练和预测\n",
      "[00:16:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:16:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:17:14,660 13912 1233114567.py[line:441] - INFO: 第12轮训练和预测结束\n",
      "2022-05-15 00:17:14,765 13912 1233114567.py[line:434] - INFO: 开始第13轮训练和预测\n",
      "[00:17:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:17:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:17:31,410 13912 1233114567.py[line:441] - INFO: 第13轮训练和预测结束\n",
      "2022-05-15 00:17:31,514 13912 1233114567.py[line:434] - INFO: 开始第14轮训练和预测\n",
      "[00:17:31] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:17:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:17:48,042 13912 1233114567.py[line:441] - INFO: 第14轮训练和预测结束\n",
      "2022-05-15 00:17:48,147 13912 1233114567.py[line:434] - INFO: 开始第15轮训练和预测\n",
      "[00:17:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:17:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:18:04,413 13912 1233114567.py[line:441] - INFO: 第15轮训练和预测结束\n",
      "2022-05-15 00:18:04,515 13912 1233114567.py[line:434] - INFO: 开始第16轮训练和预测\n",
      "[00:18:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:18:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:18:21,202 13912 1233114567.py[line:441] - INFO: 第16轮训练和预测结束\n",
      "2022-05-15 00:18:21,304 13912 1233114567.py[line:434] - INFO: 开始第17轮训练和预测\n",
      "[00:18:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:18:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:18:37,907 13912 1233114567.py[line:441] - INFO: 第17轮训练和预测结束\n",
      "2022-05-15 00:18:38,007 13912 1233114567.py[line:434] - INFO: 开始第18轮训练和预测\n",
      "[00:18:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:18:38] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:18:54,495 13912 1233114567.py[line:441] - INFO: 第18轮训练和预测结束\n",
      "2022-05-15 00:18:54,599 13912 1233114567.py[line:434] - INFO: 开始第19轮训练和预测\n",
      "[00:18:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:18:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:19:11,036 13912 1233114567.py[line:441] - INFO: 第19轮训练和预测结束\n",
      "2022-05-15 00:19:11,140 13912 1233114567.py[line:434] - INFO: 开始第20轮训练和预测\n",
      "[00:19:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:19:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:19:27,919 13912 1233114567.py[line:441] - INFO: 第20轮训练和预测结束\n",
      "2022-05-15 00:19:28,021 13912 1233114567.py[line:434] - INFO: 开始第21轮训练和预测\n",
      "[00:19:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:19:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:19:44,538 13912 1233114567.py[line:441] - INFO: 第21轮训练和预测结束\n",
      "2022-05-15 00:19:44,642 13912 1233114567.py[line:434] - INFO: 开始第22轮训练和预测\n",
      "[00:19:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:19:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:20:01,267 13912 1233114567.py[line:441] - INFO: 第22轮训练和预测结束\n",
      "2022-05-15 00:20:01,381 13912 1233114567.py[line:434] - INFO: 开始第23轮训练和预测\n",
      "[00:20:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:20:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:20:17,891 13912 1233114567.py[line:441] - INFO: 第23轮训练和预测结束\n",
      "2022-05-15 00:20:17,996 13912 1233114567.py[line:434] - INFO: 开始第24轮训练和预测\n",
      "[00:20:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:20:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:20:34,333 13912 1233114567.py[line:441] - INFO: 第24轮训练和预测结束\n",
      "2022-05-15 00:20:34,438 13912 1233114567.py[line:434] - INFO: 开始第25轮训练和预测\n",
      "[00:20:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:20:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:20:50,983 13912 1233114567.py[line:441] - INFO: 第25轮训练和预测结束\n",
      "2022-05-15 00:20:51,089 13912 1233114567.py[line:434] - INFO: 开始第26轮训练和预测\n",
      "[00:20:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:20:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:21:07,582 13912 1233114567.py[line:441] - INFO: 第26轮训练和预测结束\n",
      "2022-05-15 00:21:07,682 13912 1233114567.py[line:434] - INFO: 开始第27轮训练和预测\n",
      "[00:21:07] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:21:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:21:23,945 13912 1233114567.py[line:441] - INFO: 第27轮训练和预测结束\n",
      "2022-05-15 00:21:24,049 13912 1233114567.py[line:434] - INFO: 开始第28轮训练和预测\n",
      "[00:21:24] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:21:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:21:40,572 13912 1233114567.py[line:441] - INFO: 第28轮训练和预测结束\n",
      "2022-05-15 00:21:40,678 13912 1233114567.py[line:434] - INFO: 开始第29轮训练和预测\n",
      "[00:21:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:21:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:21:57,170 13912 1233114567.py[line:441] - INFO: 第29轮训练和预测结束\n",
      "2022-05-15 00:21:57,279 13912 1233114567.py[line:434] - INFO: 开始第30轮训练和预测\n",
      "[00:21:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:21:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:22:13,696 13912 1233114567.py[line:441] - INFO: 第30轮训练和预测结束\n",
      "2022-05-15 00:22:13,797 13912 1233114567.py[line:434] - INFO: 开始第31轮训练和预测\n",
      "[00:22:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:22:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:22:30,276 13912 1233114567.py[line:441] - INFO: 第31轮训练和预测结束\n",
      "2022-05-15 00:22:30,381 13912 1233114567.py[line:434] - INFO: 开始第32轮训练和预测\n",
      "[00:22:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:22:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:22:46,608 13912 1233114567.py[line:441] - INFO: 第32轮训练和预测结束\n",
      "2022-05-15 00:22:46,712 13912 1233114567.py[line:434] - INFO: 开始第33轮训练和预测\n",
      "[00:22:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:22:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:23:03,236 13912 1233114567.py[line:441] - INFO: 第33轮训练和预测结束\n",
      "2022-05-15 00:23:03,341 13912 1233114567.py[line:434] - INFO: 开始第34轮训练和预测\n",
      "[00:23:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:23:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:23:19,855 13912 1233114567.py[line:441] - INFO: 第34轮训练和预测结束\n",
      "2022-05-15 00:23:19,957 13912 1233114567.py[line:434] - INFO: 开始第35轮训练和预测\n",
      "[00:23:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:23:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:23:36,505 13912 1233114567.py[line:441] - INFO: 第35轮训练和预测结束\n",
      "2022-05-15 00:23:36,612 13912 1233114567.py[line:434] - INFO: 开始第36轮训练和预测\n",
      "[00:23:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:23:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:23:53,214 13912 1233114567.py[line:441] - INFO: 第36轮训练和预测结束\n",
      "2022-05-15 00:23:53,325 13912 1233114567.py[line:434] - INFO: 开始第37轮训练和预测\n",
      "[00:23:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:23:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:24:09,516 13912 1233114567.py[line:441] - INFO: 第37轮训练和预测结束\n",
      "2022-05-15 00:24:09,620 13912 1233114567.py[line:434] - INFO: 开始第38轮训练和预测\n",
      "[00:24:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:24:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:24:26,307 13912 1233114567.py[line:441] - INFO: 第38轮训练和预测结束\n",
      "2022-05-15 00:24:26,414 13912 1233114567.py[line:434] - INFO: 开始第39轮训练和预测\n",
      "[00:24:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:24:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:24:43,092 13912 1233114567.py[line:441] - INFO: 第39轮训练和预测结束\n",
      "2022-05-15 00:24:43,200 13912 1233114567.py[line:434] - INFO: 开始第40轮训练和预测\n",
      "[00:24:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:24:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:24:59,936 13912 1233114567.py[line:441] - INFO: 第40轮训练和预测结束\n",
      "2022-05-15 00:25:00,042 13912 1233114567.py[line:434] - INFO: 开始第41轮训练和预测\n",
      "[00:25:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:25:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:25:16,748 13912 1233114567.py[line:441] - INFO: 第41轮训练和预测结束\n",
      "2022-05-15 00:25:16,854 13912 1233114567.py[line:434] - INFO: 开始第42轮训练和预测\n",
      "[00:25:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:25:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:25:33,511 13912 1233114567.py[line:441] - INFO: 第42轮训练和预测结束\n",
      "2022-05-15 00:25:33,618 13912 1233114567.py[line:434] - INFO: 开始第43轮训练和预测\n",
      "[00:25:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:25:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:25:50,181 13912 1233114567.py[line:441] - INFO: 第43轮训练和预测结束\n",
      "2022-05-15 00:25:50,283 13912 1233114567.py[line:434] - INFO: 开始第44轮训练和预测\n",
      "[00:25:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:25:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:26:06,710 13912 1233114567.py[line:441] - INFO: 第44轮训练和预测结束\n",
      "2022-05-15 00:26:06,812 13912 1233114567.py[line:434] - INFO: 开始第45轮训练和预测\n",
      "[00:26:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:26:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:26:23,144 13912 1233114567.py[line:441] - INFO: 第45轮训练和预测结束\n",
      "2022-05-15 00:26:23,246 13912 1233114567.py[line:434] - INFO: 开始第46轮训练和预测\n",
      "[00:26:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:26:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:26:40,034 13912 1233114567.py[line:441] - INFO: 第46轮训练和预测结束\n",
      "2022-05-15 00:26:40,142 13912 1233114567.py[line:434] - INFO: 开始第47轮训练和预测\n",
      "[00:26:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:26:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:26:56,838 13912 1233114567.py[line:441] - INFO: 第47轮训练和预测结束\n",
      "2022-05-15 00:26:56,943 13912 1233114567.py[line:434] - INFO: 开始第48轮训练和预测\n",
      "[00:26:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:26:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:27:13,578 13912 1233114567.py[line:441] - INFO: 第48轮训练和预测结束\n",
      "2022-05-15 00:27:13,686 13912 1233114567.py[line:434] - INFO: 开始第49轮训练和预测\n",
      "[00:27:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:27:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:27:30,228 13912 1233114567.py[line:441] - INFO: 第49轮训练和预测结束\n",
      "2022-05-15 00:27:30,337 13912 1233114567.py[line:434] - INFO: 开始第50轮训练和预测\n",
      "[00:27:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:27:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:27:46,953 13912 1233114567.py[line:441] - INFO: 第50轮训练和预测结束\n",
      "2022-05-15 00:27:47,055 13912 1233114567.py[line:434] - INFO: 开始第51轮训练和预测\n",
      "[00:27:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:27:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:28:03,718 13912 1233114567.py[line:441] - INFO: 第51轮训练和预测结束\n",
      "2022-05-15 00:28:03,821 13912 1233114567.py[line:434] - INFO: 开始第52轮训练和预测\n",
      "[00:28:03] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:28:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:28:20,265 13912 1233114567.py[line:441] - INFO: 第52轮训练和预测结束\n",
      "2022-05-15 00:28:20,366 13912 1233114567.py[line:434] - INFO: 开始第53轮训练和预测\n",
      "[00:28:20] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:28:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:28:37,160 13912 1233114567.py[line:441] - INFO: 第53轮训练和预测结束\n",
      "2022-05-15 00:28:37,264 13912 1233114567.py[line:434] - INFO: 开始第54轮训练和预测\n",
      "[00:28:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:28:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:28:53,971 13912 1233114567.py[line:441] - INFO: 第54轮训练和预测结束\n",
      "2022-05-15 00:28:54,079 13912 1233114567.py[line:434] - INFO: 开始第55轮训练和预测\n",
      "[00:28:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:28:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:29:11,002 13912 1233114567.py[line:441] - INFO: 第55轮训练和预测结束\n",
      "2022-05-15 00:29:11,107 13912 1233114567.py[line:434] - INFO: 开始第56轮训练和预测\n",
      "[00:29:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:29:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:29:28,153 13912 1233114567.py[line:441] - INFO: 第56轮训练和预测结束\n",
      "2022-05-15 00:29:28,256 13912 1233114567.py[line:434] - INFO: 开始第57轮训练和预测\n",
      "[00:29:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:29:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:29:45,254 13912 1233114567.py[line:441] - INFO: 第57轮训练和预测结束\n",
      "2022-05-15 00:29:45,357 13912 1233114567.py[line:434] - INFO: 开始第58轮训练和预测\n",
      "[00:29:45] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:29:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:30:02,440 13912 1233114567.py[line:441] - INFO: 第58轮训练和预测结束\n",
      "2022-05-15 00:30:02,552 13912 1233114567.py[line:434] - INFO: 开始第59轮训练和预测\n",
      "[00:30:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:30:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:30:19,077 13912 1233114567.py[line:441] - INFO: 第59轮训练和预测结束\n",
      "2022-05-15 00:30:19,179 13912 1233114567.py[line:434] - INFO: 开始第60轮训练和预测\n",
      "[00:30:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:30:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:30:35,896 13912 1233114567.py[line:441] - INFO: 第60轮训练和预测结束\n",
      "2022-05-15 00:30:36,001 13912 1233114567.py[line:434] - INFO: 开始第61轮训练和预测\n",
      "[00:30:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:30:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:30:52,890 13912 1233114567.py[line:441] - INFO: 第61轮训练和预测结束\n",
      "2022-05-15 00:30:52,989 13912 1233114567.py[line:434] - INFO: 开始第62轮训练和预测\n",
      "[00:30:52] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:30:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:31:09,512 13912 1233114567.py[line:441] - INFO: 第62轮训练和预测结束\n",
      "2022-05-15 00:31:09,614 13912 1233114567.py[line:434] - INFO: 开始第63轮训练和预测\n",
      "[00:31:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:31:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:31:26,230 13912 1233114567.py[line:441] - INFO: 第63轮训练和预测结束\n",
      "2022-05-15 00:31:26,336 13912 1233114567.py[line:434] - INFO: 开始第64轮训练和预测\n",
      "[00:31:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:31:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:31:42,875 13912 1233114567.py[line:441] - INFO: 第64轮训练和预测结束\n",
      "2022-05-15 00:31:42,988 13912 1233114567.py[line:434] - INFO: 开始第65轮训练和预测\n",
      "[00:31:42] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:31:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:31:59,631 13912 1233114567.py[line:441] - INFO: 第65轮训练和预测结束\n",
      "2022-05-15 00:31:59,737 13912 1233114567.py[line:434] - INFO: 开始第66轮训练和预测\n",
      "[00:31:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:31:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:32:16,315 13912 1233114567.py[line:441] - INFO: 第66轮训练和预测结束\n",
      "2022-05-15 00:32:16,420 13912 1233114567.py[line:434] - INFO: 开始第67轮训练和预测\n",
      "[00:32:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:32:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:32:32,770 13912 1233114567.py[line:441] - INFO: 第67轮训练和预测结束\n",
      "2022-05-15 00:32:32,868 13912 1233114567.py[line:434] - INFO: 开始第68轮训练和预测\n",
      "[00:32:32] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:32:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:32:51,140 13912 1233114567.py[line:441] - INFO: 第68轮训练和预测结束\n",
      "2022-05-15 00:32:51,250 13912 1233114567.py[line:434] - INFO: 开始第69轮训练和预测\n",
      "[00:32:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:32:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:33:07,819 13912 1233114567.py[line:441] - INFO: 第69轮训练和预测结束\n",
      "2022-05-15 00:33:07,929 13912 1233114567.py[line:434] - INFO: 开始第70轮训练和预测\n",
      "[00:33:07] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:33:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:33:24,250 13912 1233114567.py[line:441] - INFO: 第70轮训练和预测结束\n",
      "2022-05-15 00:33:24,355 13912 1233114567.py[line:434] - INFO: 开始第71轮训练和预测\n",
      "[00:33:24] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:33:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:33:40,994 13912 1233114567.py[line:441] - INFO: 第71轮训练和预测结束\n",
      "2022-05-15 00:33:41,110 13912 1233114567.py[line:434] - INFO: 开始第72轮训练和预测\n",
      "[00:33:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:33:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:33:57,450 13912 1233114567.py[line:441] - INFO: 第72轮训练和预测结束\n",
      "2022-05-15 00:33:57,557 13912 1233114567.py[line:434] - INFO: 开始第73轮训练和预测\n",
      "[00:33:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:33:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:34:14,070 13912 1233114567.py[line:441] - INFO: 第73轮训练和预测结束\n",
      "2022-05-15 00:34:14,172 13912 1233114567.py[line:434] - INFO: 开始第74轮训练和预测\n",
      "[00:34:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:34:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:34:30,867 13912 1233114567.py[line:441] - INFO: 第74轮训练和预测结束\n",
      "2022-05-15 00:34:30,987 13912 1233114567.py[line:434] - INFO: 开始第75轮训练和预测\n",
      "[00:34:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:34:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:34:47,803 13912 1233114567.py[line:441] - INFO: 第75轮训练和预测结束\n",
      "2022-05-15 00:34:47,911 13912 1233114567.py[line:434] - INFO: 开始第76轮训练和预测\n",
      "[00:34:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:34:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:35:04,467 13912 1233114567.py[line:441] - INFO: 第76轮训练和预测结束\n",
      "2022-05-15 00:35:04,574 13912 1233114567.py[line:434] - INFO: 开始第77轮训练和预测\n",
      "[00:35:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:35:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:35:21,082 13912 1233114567.py[line:441] - INFO: 第77轮训练和预测结束\n",
      "2022-05-15 00:35:21,193 13912 1233114567.py[line:434] - INFO: 开始第78轮训练和预测\n",
      "[00:35:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:35:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:35:37,382 13912 1233114567.py[line:441] - INFO: 第78轮训练和预测结束\n",
      "2022-05-15 00:35:37,498 13912 1233114567.py[line:434] - INFO: 开始第79轮训练和预测\n",
      "[00:35:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:35:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:35:53,881 13912 1233114567.py[line:441] - INFO: 第79轮训练和预测结束\n",
      "2022-05-15 00:35:53,985 13912 1233114567.py[line:434] - INFO: 开始第80轮训练和预测\n",
      "[00:35:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:35:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:36:10,512 13912 1233114567.py[line:441] - INFO: 第80轮训练和预测结束\n",
      "2022-05-15 00:36:10,616 13912 1233114567.py[line:434] - INFO: 开始第81轮训练和预测\n",
      "[00:36:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:36:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:36:26,923 13912 1233114567.py[line:441] - INFO: 第81轮训练和预测结束\n",
      "2022-05-15 00:36:27,032 13912 1233114567.py[line:434] - INFO: 开始第82轮训练和预测\n",
      "[00:36:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:36:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:36:43,256 13912 1233114567.py[line:441] - INFO: 第82轮训练和预测结束\n",
      "2022-05-15 00:36:43,366 13912 1233114567.py[line:434] - INFO: 开始第83轮训练和预测\n",
      "[00:36:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:36:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:36:59,894 13912 1233114567.py[line:441] - INFO: 第83轮训练和预测结束\n",
      "2022-05-15 00:37:00,007 13912 1233114567.py[line:434] - INFO: 开始第84轮训练和预测\n",
      "[00:37:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:37:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:37:16,574 13912 1233114567.py[line:441] - INFO: 第84轮训练和预测结束\n",
      "2022-05-15 00:37:16,677 13912 1233114567.py[line:434] - INFO: 开始第85轮训练和预测\n",
      "[00:37:16] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:37:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:37:33,165 13912 1233114567.py[line:441] - INFO: 第85轮训练和预测结束\n",
      "2022-05-15 00:37:33,276 13912 1233114567.py[line:434] - INFO: 开始第86轮训练和预测\n",
      "[00:37:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:37:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:37:49,999 13912 1233114567.py[line:441] - INFO: 第86轮训练和预测结束\n",
      "2022-05-15 00:37:50,121 13912 1233114567.py[line:434] - INFO: 开始第87轮训练和预测\n",
      "[00:37:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:37:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:38:06,812 13912 1233114567.py[line:441] - INFO: 第87轮训练和预测结束\n",
      "2022-05-15 00:38:06,922 13912 1233114567.py[line:434] - INFO: 开始第88轮训练和预测\n",
      "[00:38:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:38:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:38:23,748 13912 1233114567.py[line:441] - INFO: 第88轮训练和预测结束\n",
      "2022-05-15 00:38:23,854 13912 1233114567.py[line:434] - INFO: 开始第89轮训练和预测\n",
      "[00:38:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:38:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:38:40,549 13912 1233114567.py[line:441] - INFO: 第89轮训练和预测结束\n",
      "2022-05-15 00:38:40,661 13912 1233114567.py[line:434] - INFO: 开始第90轮训练和预测\n",
      "[00:38:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:38:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:38:57,221 13912 1233114567.py[line:441] - INFO: 第90轮训练和预测结束\n",
      "2022-05-15 00:38:57,328 13912 1233114567.py[line:434] - INFO: 开始第91轮训练和预测\n",
      "[00:38:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:38:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:39:14,121 13912 1233114567.py[line:441] - INFO: 第91轮训练和预测结束\n",
      "2022-05-15 00:39:14,229 13912 1233114567.py[line:434] - INFO: 开始第92轮训练和预测\n",
      "[00:39:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:39:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:39:30,662 13912 1233114567.py[line:441] - INFO: 第92轮训练和预测结束\n",
      "2022-05-15 00:39:30,768 13912 1233114567.py[line:434] - INFO: 开始第93轮训练和预测\n",
      "[00:39:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:39:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:39:47,314 13912 1233114567.py[line:441] - INFO: 第93轮训练和预测结束\n",
      "2022-05-15 00:39:47,419 13912 1233114567.py[line:434] - INFO: 开始第94轮训练和预测\n",
      "[00:39:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:39:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:40:04,138 13912 1233114567.py[line:441] - INFO: 第94轮训练和预测结束\n",
      "2022-05-15 00:40:04,252 13912 1233114567.py[line:434] - INFO: 开始第95轮训练和预测\n",
      "[00:40:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:40:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:40:20,842 13912 1233114567.py[line:441] - INFO: 第95轮训练和预测结束\n",
      "2022-05-15 00:40:20,957 13912 1233114567.py[line:434] - INFO: 开始第96轮训练和预测\n",
      "[00:40:20] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:40:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:40:37,408 13912 1233114567.py[line:441] - INFO: 第96轮训练和预测结束\n",
      "2022-05-15 00:40:37,518 13912 1233114567.py[line:434] - INFO: 开始第97轮训练和预测\n",
      "[00:40:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:40:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:40:54,110 13912 1233114567.py[line:441] - INFO: 第97轮训练和预测结束\n",
      "2022-05-15 00:40:54,217 13912 1233114567.py[line:434] - INFO: 开始第98轮训练和预测\n",
      "[00:40:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:40:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 00:41:10,903 13912 1233114567.py[line:441] - INFO: 第98轮训练和预测结束\n",
      "2022-05-15 00:41:11,010 13912 1233114567.py[line:434] - INFO: 开始第99轮训练和预测\n",
      "[00:41:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:41:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-15 00:41:27,674 13912 1233114567.py[line:441] - INFO: 第99轮训练和预测结束\n",
      "2022-05-15 00:41:27,715 13912 1233114567.py[line:447] - INFO: 训练集评估效果: \n",
      "2022-05-15 00:41:27,723 13912 1233114567.py[line:334] - INFO: Label 0:   Precision  0.42, Recall  0.55, F1  0.48\n",
      "2022-05-15 00:41:27,726 13912 1233114567.py[line:334] - INFO: Label 1:   Precision  0.70, Recall  0.64, F1  0.67\n",
      "2022-05-15 00:41:27,728 13912 1233114567.py[line:334] - INFO: Label 2:   Precision  0.96, Recall  0.92, F1  0.94\n",
      "2022-05-15 00:41:27,730 13912 1233114567.py[line:334] - INFO: Label 3:   Precision  0.86, Recall  0.93, F1  0.89\n",
      "2022-05-15 00:41:27,730 13912 1233114567.py[line:335] - INFO: macro_f1: 0.6261152686236977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgb训练预测\n",
    "# 使用303特征\n",
    "# 100 500 0.6309\n",
    "# 50 700 0.6261\n",
    "# 全部特征\n",
    "# 0.6261\n",
    "predictions = xgbRandomTrainPredict(temp_feature_df, val_feature_df, val_feature_df[['sn', 'fault_time', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f219e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13 01:45:40,780 15968 3915516630.py[line:34] - INFO: 开始第0轮训练和预测\n",
      "[01:45:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:45:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2022-05-13 01:45:46,567 15968 3915516630.py[line:41] - INFO: 第0轮训练和预测结束\n",
      "2022-05-13 01:45:46,590 15968 3915516630.py[line:34] - INFO: 开始第1轮训练和预测\n",
      "[01:45:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:45:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m sub_train_data \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(sub_train_feature,label \u001b[38;5;241m=\u001b[39m sub_train_label)\n\u001b[0;32m     34\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m开始第\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m轮训练和预测\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28miter\u001b[39m))\n\u001b[1;32m---> 35\u001b[0m sub_xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m sub_test_pred \u001b[38;5;241m=\u001b[39m sub_xgb_model\u001b[38;5;241m.\u001b[39mpredict(test_feature)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Log_diagnosis_python\\lib\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_feature_df = temp_feature_df\n",
    "test_feature_df = val_feature_df\n",
    "label_df = val_feature_df[['sn', 'fault_time', 'label']]\n",
    "\n",
    "\n",
    "## 每个子模型样本均衡，利用投票规则生成最终预测\n",
    "random.seed(0)\n",
    "N = 100 # number of the models\n",
    "num_sample = 500 # number of samples for each label\n",
    "train_feature_df\n",
    "\n",
    "\n",
    "_label0_index_list = list(train_feature_df[train_feature_df['label'] == 0].index)\n",
    "_label1_index_list = list(train_feature_df[train_feature_df['label'] == 1].index)\n",
    "_label2_index_list = list(train_feature_df[train_feature_df['label'] == 2].index)\n",
    "_label3_index_list = list(train_feature_df[train_feature_df['label'] == 3].index)\n",
    "feature_name_list = list(train_feature_df.columns)[0:-3]\n",
    "test_feature = np.array(test_feature_df[feature_name_list])\n",
    "test_feature = xgb.DMatrix(test_feature)\n",
    "prediction_df = test_feature_df[['sn', 'fault_time']]\n",
    "\n",
    "for iter in np.arange(N):\n",
    "    idx_0 = random.sample(_label0_index_list, num_sample)\n",
    "    idx_1 = random.sample(_label1_index_list, num_sample)\n",
    "    idx_2 = random.sample(_label2_index_list, num_sample)\n",
    "    idx_3 = random.sample(_label3_index_list, num_sample)\n",
    "    idx = np.hstack((idx_0, idx_1, idx_2, idx_3))\n",
    "    random.shuffle(idx)\n",
    "    sub_train_feature_df = train_feature_df.loc[idx, :]\n",
    "    sub_train_feature = np.array(sub_train_feature_df[feature_name_list])\n",
    "    sub_train_label = np.array(sub_train_feature_df['label'])\n",
    "    sub_train_data = xgb.DMatrix(sub_train_feature,label = sub_train_label)\n",
    "\n",
    "    logger.info('开始第{}轮训练和预测'.format(iter))\n",
    "    sub_xgb_model = xgb.train(xgb_params, sub_train_data, num_boost_round=500)\n",
    "    sub_test_pred = sub_xgb_model.predict(test_feature)\n",
    "    if iter == 0:\n",
    "        val_pred = sub_test_pred\n",
    "    else:\n",
    "        val_pred = np.vstack((val_pred, sub_test_pred))\n",
    "    logger.info('第{}轮训练和预测结束'.format(iter))\n",
    "\n",
    "# 训练集指标评估\n",
    "final_pred = [np.argmax(np.bincount(val_pred[:, i].astype(int))) for i in np.arange(val_pred.shape[1])]\n",
    "final_pred = np.array(final_pred).astype(int)\n",
    "prediction_df['label'] = final_pred\n",
    "logger.info('训练集评估效果: ')\n",
    "macro_f1(label_df, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0105e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     4,     5,     6,     7,     8,     9,\n",
       "               10,\n",
       "            ...\n",
       "            16593, 16594, 16595, 16596, 16597, 16598, 16599, 16600, 16601,\n",
       "            16603],\n",
       "           dtype='int64', length=11617)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_df.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Log_diagosis_python",
   "language": "python",
   "name": "log_diagosis_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
